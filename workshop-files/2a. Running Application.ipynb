{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a. Run your application\n",
    "\n",
    "With your data loaded and embedded, you are now ready to run your application. This application is built using Streamlit. \n",
    "\n",
    "When you are ready, run this notebook to start the application. Switch to the *application tab name tbd* to begin using your chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['STREAMLIT_GENERAL_EMAIL'] = \"\"\n",
    "os.environ['STREAMLIT_THEME_PRIMARYCOLOR'] = \"#5863ff\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  You can now view your Streamlit app in your browser.\n",
      "\n",
      "  Local URL: http://localhost:8080\n",
      "  Network URL: http://172.22.18.102:8080\n",
      "\n",
      "  For better performance, install the Watchdog module:\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/drobinso/Desktop/GS2025/gs25-ai-workshop-repurp/exercise/2. Building a Simple Chat.py:12: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(temperature=0.7)\n",
      "/Users/drobinso/Desktop/GS2025/gs25-ai-workshop-repurp/exercise/2. Building a Simple Chat.py:13: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  st.info(llm(input_text))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Stopping...\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# If you're using a container, mac, or linux machine --- run this cell\n",
    "streamlit run '2. Building a Simple Chat.py' --server.port 8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
