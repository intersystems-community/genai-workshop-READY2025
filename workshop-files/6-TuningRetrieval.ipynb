{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "682b0195",
   "metadata": {},
   "source": [
    "## 6. Tuning Your Retrieval Mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebae88ef",
   "metadata": {},
   "source": [
    "Let's pivot to a more complex data set for the final two sections of this workshop. Please stop all other python kernels before you start working on this notebook.\n",
    "\n",
    "You're about to explore how we can enhance the way we retrieve relevant patient data from a medical dataset of patient encounters using various techniques. You will start by running a basic vector search in InterSystems IRIS, similar to earlier sections. Then you'll refine your results with advanced methods like weighted scoring and hybrid search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3202ca8a",
   "metadata": {},
   "source": [
    "### InterSystems IRIS Vector Search: A Recap\n",
    "To recap, InterSystems IRIS Vector Search allows us to store and query high-dimensional vector embeddings within a relational database. These embeddings represent unstructured data like clinical notes as numerical vectors, enabling semantic similarity comparisons. This means we can find patient encounters that are contextually similar to a query, using SQL operations enhanced by vectors.\n",
    "\n",
    "By integrating these capabilities into standard SQL operations, InterSystems IRIS transforms your relational database into a high-performance hybrid vector database ready to support next-generation AI applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822ddf82",
   "metadata": {},
   "source": [
    "### Step 1: Connecting to InterSystems IRIS and Viewing the Dataset\n",
    "Let's start by connecting to the InterSystems IRIS database to access our medical dataset.\n",
    "\n",
    "This new data set includes ~1,500 patient encounters, each with structured and coded medical data. With each encounter, however, is also a generated clinical summary note that provides more context about the patient. This might include things such as their commuting situation, their mood during the encounter, or other information not easily categorized into a structured encounter record. They are, however, still relatively lean and simple clinician notes.\n",
    "\n",
    "Run the block of code below to initiate a connection to InterSystems IRIS and view a snippet of this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b612b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "username = '_SYSTEM'\n",
    "password = 'SYS'\n",
    "hostname = 'IRIS'\n",
    "port = 1972\n",
    "namespace = 'IRISAPP'\n",
    "CONNECTION_STRING = f\"iris://{username}:{password}@{hostname}:{port}/{namespace}\"\n",
    "engine = create_engine(CONNECTION_STRING)\n",
    "\n",
    "df = pd.read_sql(\"SELECT * FROM GenAI.Encounters\", engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16017fd7",
   "metadata": {},
   "source": [
    "Notice that in addition to structured data—such as codes, costs, and standardized descriptions of the encounters—there are also columns with unstructured observations and notes, and accompanying vector embeddings. These vector embeddings will help a generative AI application retrieve relevant chunks of data from this set of patient encounters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d31ec47",
   "metadata": {},
   "source": [
    "### Step 2: Running a Simple Vector Search\n",
    "In this step, we’ll execute a basic vector search to find patient encounters similar to a query input.\n",
    "\n",
    "A simple vector search demonstrates how InterSystems IRIS compares embeddings to find semantically relevant results. For example, querying for something like \"Headache\" would return encounters with similar clinical notes, even if the exact words differ. This is the starting point for understanding retrieval based on meaning rather than keywords\n",
    "\n",
    "First, run the following line of code to select the sentence transformer model that will be used to create an embedding from your search term. The embedding model you use to embed your search queries should be compatible with the model used to create embeddings in your data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d6d3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01801dba",
   "metadata": {},
   "source": [
    "Run the next module, optionally replacing \"Headache\" with a search term of your choice. This module will create and print an embedding for the search term you have entered. You will see that the embedding, even for a simple search term, consists of 384 dimensions—the number of dimensions in the FastEmbed embeddings model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f746e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_search = \"Headache\"\n",
    "search_vector = model.encode(note_search, normalize_embeddings=True).tolist() # Convert search phrase into a vector\n",
    "print(search_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c81acfe",
   "metadata": {},
   "source": [
    "Now let's run a vector search against our CLINICAL_NOTES field using your search term. With the code below, you will retrieve the top three chunks from the CLINICAL_NOTES field in your data set that are deemed most similar to the search term you provided. The results will be displayed in a Pandas DataFrame for easy viewing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c76093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "vector_str = \",\".join(str(x) for x in search_vector)\n",
    "## print(vector_str)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    with conn.begin():\n",
    "        sql = text(\"\"\"\n",
    "            SELECT TOP 3 ENCOUNTER_ID, CLINICAL_NOTES\n",
    "            FROM GenAI.encounters\n",
    "            ORDER BY VECTOR_DOT_PRODUCT(CLINICAL_NOTES_Vector, TO_VECTOR(:search_vector)) DESC\n",
    "        \"\"\")\n",
    "        results = conn.execute(sql, {\"search_vector\": vector_str}).fetchall()\n",
    "\n",
    "# Display results\n",
    "df = pd.DataFrame(results)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d63c771",
   "metadata": {},
   "source": [
    "We can also run a search using only SQL by using the `EMBEDDING` function. Go to the InterSystems IRIS management portal using the *IRIS* tab and switch the namespace to *IRISAPP*.\n",
    "\n",
    "First, we need to setup the embedding config. This will update the configuration table and download the model into IRIS. Copy-paste the following SQL block and execute it in the management portal. This might take a minute to run while the model is being installed.\n",
    "\n",
    "```sql\n",
    "INSERT INTO %Embedding.Config (Name, Configuration, EmbeddingClass, Description)\n",
    "VALUES ('sentence-transformers/all-MiniLM-L6-v2',\n",
    "        '{\"modelName\": \"sentence-transformers/all-MiniLM-L6-v2\", \"hfCachePath\": \"/home/irisowner/dev\", \"checkTokenCount\": false}',\n",
    "        '%Embedding.SentenceTransformers',\n",
    "        'a small SentenceTransformers embedding model')\n",
    "```\n",
    "\n",
    "Now that we have the embedding configuration in place, we can execute SQL queries without having to create the embeddings manually using the new `EMBEDDING` funcion, which leverages Embedded Python. Execute the following SQL in the management portal:\n",
    "\n",
    "```sql\n",
    "Select top 10 VECTOR_DOT_PRODUCT(CLINICAL_NOTES_Vector, \n",
    "                                 embedding('diabetes','sentence-transformers/all-MiniLM-L6-v2')) dot_product,\n",
    "                                 encounter_id, clinical_notes\n",
    "FROM GenAI.encounters\n",
    "order by VECTOR_DOT_PRODUCT(CLINICAL_NOTES_Vector, embedding('diabetes','sentence-transformers/all-MiniLM-L6-v2')) desc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64968f8",
   "metadata": {},
   "source": [
    "### Step 3: Searching across multiple vectorized fields\n",
    "Let's now consider that you may want to search across more than just your `CLINICAL_NOTES` field. To improve relevance, we’ll break down similarity across different data categories (notes, observations, etc.) to see which aspects contribute most to the match. This will help us fine-tune our search.\n",
    "\n",
    "In the block below, you will notice that similarities are being calculated between your search term and all five vectorized fields in the data set. Then, the results are being ordered by the greatest similarity match.\n",
    "\n",
    "In the result set that follows, explore the similarity scores provided. Sometimes one field provides a particularly good match, while others do not.\n",
    "\n",
    "Enter whatever search term you would like in the `note_search` variable. Feel free to play around with multiple searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc1549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_search = \"Pregnancy complications\"\n",
    "search_vector = model.encode(note_search, normalize_embeddings=True).tolist() # Convert search phrase into a vector\n",
    "## print(search_vector)\n",
    "\n",
    "vector_str = \",\".join(str(x) for x in search_vector) \n",
    "\n",
    "with engine.connect() as conn:\n",
    "    with conn.begin():\n",
    "        sql = text(\"\"\"\n",
    "            SELECT TOP 5\n",
    "                ENCOUNTER_ID,\n",
    "                CLINICAL_NOTES,\n",
    "                DESCRIPTION_OBSERVATIONS,\n",
    "                DESCRIPTION_CONDITIONS,\n",
    "                DESCRIPTION_PROCEDURES,\n",
    "                DESCRIPTION_MEDICATIONS,\n",
    "                VECTOR_DOT_PRODUCT (CLINICAL_NOTES_Vector, TO_VECTOR(:search_vector))\n",
    "                    AS sim_notes,\n",
    "                VECTOR_DOT_PRODUCT(DESCRIPTION_OBSERVATIONS_Vector, TO_VECTOR(:search_vector))\n",
    "                    AS sim_obs,\n",
    "                VECTOR_DOT_PRODUCT(DESCRIPTION_CONDITIONS_Vector,   TO_VECTOR(:search_vector))\n",
    "                    AS sim_cond,\n",
    "                VECTOR_DOT_PRODUCT(DESCRIPTION_PROCEDURES_Vector,   TO_VECTOR(:search_vector))\n",
    "                    AS sim_proc,\n",
    "                VECTOR_DOT_PRODUCT(DESCRIPTION_MEDICATIONS_Vector,  TO_VECTOR(:search_vector))\n",
    "                    AS sim_med\n",
    "            FROM GenAI.encounters\n",
    "            ORDER BY GREATEST(\n",
    "                VECTOR_DOT_PRODUCT(CLINICAL_NOTES_Vector,           TO_VECTOR(:search_vector)),\n",
    "                VECTOR_DOT_PRODUCT(DESCRIPTION_OBSERVATIONS_Vector, TO_VECTOR(:search_vector)),\n",
    "                VECTOR_DOT_PRODUCT(DESCRIPTION_CONDITIONS_Vector,   TO_VECTOR(:search_vector)),\n",
    "                VECTOR_DOT_PRODUCT(DESCRIPTION_PROCEDURES_Vector,   TO_VECTOR(:search_vector)),\n",
    "                VECTOR_DOT_PRODUCT(DESCRIPTION_MEDICATIONS_Vector,  TO_VECTOR(:search_vector))\n",
    ") DESC\n",
    "\n",
    "        \"\"\")\n",
    "        results = conn.execute(sql, {\"search_vector\": vector_str}).fetchall()\n",
    "df = pd.DataFrame(results, columns=[\n",
    "    \"ENCOUNTER_ID\",\n",
    "    \"CLINICAL_NOTES\", \"DESCRIPTION_OBSERVATIONS\", \"DESCRIPTION_CONDITIONS\",\n",
    "    \"DESCRIPTION_PROCEDURES\", \"DESCRIPTION_MEDICATIONS\",\n",
    "    \"sim_notes\",\n",
    "    \"sim_obs\",\n",
    "    \"sim_cond\",\n",
    "    \"sim_proc\",\n",
    "    \"sim_med\"\n",
    "])\n",
    "df[\"DESCRIPTION_OBSERVATIONS\"] = df[\"DESCRIPTION_OBSERVATIONS\"].str[:250]\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4dfba4",
   "metadata": {},
   "source": [
    "Looking at the results (if you kept the default search phrase \"pregnancy complications\"), notice a few things:\n",
    "- ENCOUNTER_ID 1260 has a higher *sim_proc* score (0.235474) compared to other categories, suggesting the *procedures* described are more similar to the query\n",
    "- ENCOUNTER_ID 910 shows higher scores across *sim_notes*, *sim_cond*, and *sim_med* (all 0.235365), indicating broader relevance.\n",
    "\n",
    "This breakdown reveals varying contributions from different data types, but it’s not yet a unified ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021dc4cd",
   "metadata": {},
   "source": [
    "In the previous block, we used Vector Dot Product to determine similarity. So, what's the difference between using VECTOR DOT PRODUCT and COSINE SIMILARITY?\n",
    "\n",
    "- **Vector Dot Product:** Faster computation but sensitive to vector magnitude\n",
    "- **Cosine Similarity:** Magnitude-independent but slightly more computation\n",
    "\n",
    "Try running the block below to conduct the same search using Cosine Similarity instead of Vector Dot Product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09081c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_search = \"Pregnancy complications\"\n",
    "search_vector = model.encode(note_search, normalize_embeddings=True).tolist() # Convert search phrase into a vector\n",
    "## print(search_vector)\n",
    "\n",
    "vector_str = \",\".join(str(x) for x in search_vector) \n",
    "\n",
    "with engine.connect() as conn:\n",
    "    with conn.begin():\n",
    "        sql = text(\"\"\"\n",
    "            SELECT TOP 5\n",
    "                ENCOUNTER_ID,\n",
    "                CLINICAL_NOTES,\n",
    "                DESCRIPTION_OBSERVATIONS,\n",
    "                DESCRIPTION_CONDITIONS,\n",
    "                DESCRIPTION_PROCEDURES,\n",
    "                DESCRIPTION_MEDICATIONS,\n",
    "                VECTOR_COSINE (CLINICAL_NOTES_Vector, TO_VECTOR(:search_vector))\n",
    "                    AS sim_notes,\n",
    "                VECTOR_COSINE (DESCRIPTION_OBSERVATIONS_Vector, TO_VECTOR(:search_vector))\n",
    "                    AS sim_obs,\n",
    "                VECTOR_COSINE (DESCRIPTION_CONDITIONS_Vector,   TO_VECTOR(:search_vector))\n",
    "                    AS sim_cond,\n",
    "                VECTOR_COSINE (DESCRIPTION_PROCEDURES_Vector,   TO_VECTOR(:search_vector))\n",
    "                    AS sim_proc,\n",
    "                VECTOR_COSINE(DESCRIPTION_MEDICATIONS_Vector,  TO_VECTOR(:search_vector))\n",
    "                    AS sim_med\n",
    "            FROM GenAI.encounters\n",
    "            ORDER BY GREATEST(\n",
    "                VECTOR_COSINE (CLINICAL_NOTES_Vector,           TO_VECTOR(:search_vector)),\n",
    "                VECTOR_COSINE (DESCRIPTION_OBSERVATIONS_Vector, TO_VECTOR(:search_vector)),\n",
    "                VECTOR_COSINE (DESCRIPTION_CONDITIONS_Vector,   TO_VECTOR(:search_vector)),\n",
    "                VECTOR_COSINE (DESCRIPTION_PROCEDURES_Vector,   TO_VECTOR(:search_vector)),\n",
    "                VECTOR_COSINE (DESCRIPTION_MEDICATIONS_Vector,  TO_VECTOR(:search_vector))\n",
    ") DESC\n",
    "\n",
    "        \"\"\")\n",
    "        results = conn.execute(sql, {\"search_vector\": vector_str}).fetchall()\n",
    "df = pd.DataFrame(results, columns=[\n",
    "    \"ENCOUNTER_ID\",\n",
    "    \"CLINICAL_NOTES\", \"DESCRIPTION_OBSERVATIONS\", \"DESCRIPTION_CONDITIONS\",\n",
    "    \"DESCRIPTION_PROCEDURES\", \"DESCRIPTION_MEDICATIONS\",\n",
    "    \"sim_notes\",\n",
    "    \"sim_obs\",\n",
    "    \"sim_cond\",\n",
    "    \"sim_proc\",\n",
    "    \"sim_med\"\n",
    "])\n",
    "df[\"DESCRIPTION_OBSERVATIONS\"] = df[\"DESCRIPTION_OBSERVATIONS\"].str[:250]\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faba341",
   "metadata": {},
   "source": [
    "Notice that the queries using VECTOR_DOT_PRODUCT and VECTOR_COSINE produce the same results. This is actually expected when working with normalized embeddings.\n",
    "\n",
    "Why are the results the same? The key is in the embedding generation:\n",
    "\n",
    "`search_vector = model.encode(note_search, normalize_embeddings=True).tolist()`\n",
    "\n",
    "When you set `normalize_embeddings=True`, your model is creating unit vectors (vectors with length 1). With normalized vectors, the dot product is mathematically equivalent to cosine similarity.\n",
    "\n",
    "In the hybrid search function later, we will be using cosine similarity with normalized vectors, which is a common best practice for semantic search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcac455",
   "metadata": {},
   "source": [
    "### Step 4. Implementing Weight Adjustments for Multiple Vector Fields\n",
    "Perhaps you don't simply want a generic search across several vector fields; perhaps you want to use certain weights to more heavily factor one field over another. Let's explore this concept.\n",
    "\n",
    "Run the block below to set weights, in this case weighing observations (sim_obs) and notes (sim_notes) a bit higher than other fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeba311",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'sim_notes': 0.25,\n",
    "    'sim_obs': 0.35,\n",
    "    'sim_cond': 0.1,\n",
    "    'sim_proc': 0.2,\n",
    "    'sim_med': 0.1\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e747757",
   "metadata": {},
   "source": [
    "Now let's adjust the SQL query to multiply each similarity score by its corresponding weight, then sum them up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff8d3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_search = \"diabetes\"\n",
    "search_vector = model.encode(note_search, normalize_embeddings=True).tolist()  # Convert search phrase into a vector\n",
    "vector_str = \",\".join(str(x) for x in search_vector)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    with conn.begin():\n",
    "        sql = text(f\"\"\"\n",
    "            SELECT TOP 5\n",
    "                ENCOUNTER_ID,\n",
    "                CLINICAL_NOTES,\n",
    "                DESCRIPTION_OBSERVATIONS,\n",
    "                DESCRIPTION_CONDITIONS,\n",
    "                DESCRIPTION_PROCEDURES,\n",
    "                DESCRIPTION_MEDICATIONS,\n",
    "                sim_notes,\n",
    "                sim_obs,\n",
    "                sim_cond,\n",
    "                sim_proc,\n",
    "                sim_med,\n",
    "                (\n",
    "                    sim_notes * {weights['sim_notes']} +\n",
    "                    sim_obs * {weights['sim_obs']} +\n",
    "                    sim_cond * {weights['sim_cond']} +\n",
    "                    sim_proc * {weights['sim_proc']} +\n",
    "                    sim_med * {weights['sim_med']}\n",
    "                ) AS weighted_sim\n",
    "            FROM (\n",
    "                SELECT\n",
    "                    ENCOUNTER_ID,\n",
    "                    CLINICAL_NOTES,\n",
    "                    DESCRIPTION_OBSERVATIONS,\n",
    "                    DESCRIPTION_CONDITIONS,\n",
    "                    DESCRIPTION_PROCEDURES,\n",
    "                    DESCRIPTION_MEDICATIONS,\n",
    "                    VECTOR_DOT_PRODUCT(CLINICAL_NOTES_Vector, TO_VECTOR(:search_vector)) AS sim_notes,\n",
    "                    VECTOR_DOT_PRODUCT(DESCRIPTION_OBSERVATIONS_Vector, TO_VECTOR(:search_vector)) AS sim_obs,\n",
    "                    VECTOR_DOT_PRODUCT(DESCRIPTION_CONDITIONS_Vector, TO_VECTOR(:search_vector)) AS sim_cond,\n",
    "                    VECTOR_DOT_PRODUCT(DESCRIPTION_PROCEDURES_Vector, TO_VECTOR(:search_vector)) AS sim_proc,\n",
    "                    VECTOR_DOT_PRODUCT(DESCRIPTION_MEDICATIONS_Vector, TO_VECTOR(:search_vector)) AS sim_med\n",
    "                FROM GenAI.encounters\n",
    "            ) AS subquery\n",
    "            ORDER BY weighted_sim DESC\n",
    "        \"\"\")\n",
    "        results = conn.execute(sql, {\"search_vector\": vector_str}).fetchall()\n",
    "\n",
    "df = pd.DataFrame(results, columns=[\n",
    "    \"ENCOUNTER_ID\",\n",
    "    \"CLINICAL_NOTES\", \"DESCRIPTION_OBSERVATIONS\", \"DESCRIPTION_CONDITIONS\",\n",
    "    \"DESCRIPTION_PROCEDURES\", \"DESCRIPTION_MEDICATIONS\",\n",
    "    \"sim_notes\",\n",
    "    \"sim_obs\",\n",
    "    \"sim_cond\",\n",
    "    \"sim_proc\",\n",
    "    \"sim_med\",\n",
    "    \"weighted_sim\"\n",
    "])\n",
    "df[\"DESCRIPTION_OBSERVATIONS\"] = df[\"DESCRIPTION_OBSERVATIONS\"].str[:250]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b56fb1",
   "metadata": {},
   "source": [
    "### Step 5. Using Hybrid Search\n",
    "You can combine keyword-based search with vector-based search for more comprehensive results. For example, you can use a text search on the `note` field and combine it with the vector search for the same phrase.\n",
    "\n",
    "The hybrid search approach combines the strengths of both vector-based semantic search and traditional keyword search, which can provide more relevant results than either method alone. Vector search is good at understanding semantic meaning, while keyword search can catch exact matches that might be missed by the embedding model.\n",
    "\n",
    "You can adjust the `vector_weight` and `keyword_weight` parameters to fine-tune the balance between semantic similarity and keyword matching based on your specific use case.\n",
    "\n",
    "The block below is long; this block defines a full function for hybrid search. Feel free to inspect it, or simply run the module and proceed to the next block, where we'll experiment with `vector_weight` and `keyword_weight`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8779cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_search(query, engine, model, top_n=5, vector_weight=0.7, keyword_weight=0.3):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - query: Search query string\n",
    "    - engine: SQLAlchemy engine with connection to InterSystems IRIS\n",
    "    - model: model for embeddings\n",
    "    - top_n: Number of results to return\n",
    "    - vector_weight: Weight for vector search results (0.0 to 1.0)\n",
    "    - keyword_weight: Weight for keyword search results (0.0 to 1.0)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Perform vector search\n",
    "    search_vector = model.encode(query, normalize_embeddings=True).tolist()\n",
    "    vector_str = \",\".join(str(x) for x in search_vector)\n",
    "    \n",
    "    with engine.connect() as conn:\n",
    "        vector_sql = text(f\"\"\"\n",
    "            SELECT \n",
    "                TOP {top_n * 2}\n",
    "                ENCOUNTER_ID,\n",
    "                CLINICAL_NOTES,\n",
    "                DESCRIPTION_OBSERVATIONS,\n",
    "                DESCRIPTION_CONDITIONS,\n",
    "                DESCRIPTION_PROCEDURES,\n",
    "                DESCRIPTION_MEDICATIONS,\n",
    "                VECTOR_COSINE(CLINICAL_NOTES_Vector, TO_VECTOR(:search_vector)) AS sim_notes,\n",
    "                VECTOR_COSINE(DESCRIPTION_OBSERVATIONS_Vector, TO_VECTOR(:search_vector)) AS sim_obs,\n",
    "                VECTOR_COSINE(DESCRIPTION_CONDITIONS_Vector, TO_VECTOR(:search_vector)) AS sim_cond,\n",
    "                VECTOR_COSINE(DESCRIPTION_PROCEDURES_Vector, TO_VECTOR(:search_vector)) AS sim_proc,\n",
    "                VECTOR_COSINE(DESCRIPTION_MEDICATIONS_Vector, TO_VECTOR(:search_vector)) AS sim_med,\n",
    "                (\n",
    "                    VECTOR_COSINE(CLINICAL_NOTES_Vector, TO_VECTOR(:search_vector)) * {weights['sim_notes']} +\n",
    "                    VECTOR_COSINE(DESCRIPTION_OBSERVATIONS_Vector, TO_VECTOR(:search_vector)) * {weights['sim_obs']} +\n",
    "                    VECTOR_COSINE(DESCRIPTION_CONDITIONS_Vector, TO_VECTOR(:search_vector)) * {weights['sim_cond']} +\n",
    "                    VECTOR_COSINE(DESCRIPTION_PROCEDURES_Vector, TO_VECTOR(:search_vector)) * {weights['sim_proc']} +\n",
    "                    VECTOR_COSINE(DESCRIPTION_MEDICATIONS_Vector, TO_VECTOR(:search_vector)) * {weights['sim_med']}\n",
    "                ) AS vector_score\n",
    "            FROM GenAI.encounters\n",
    "            ORDER BY vector_score DESC\n",
    "        \"\"\")\n",
    "        \n",
    "        vector_results = conn.execute(vector_sql, {\"search_vector\": vector_str}).fetchall()\n",
    "        \n",
    "        # Step 2: Perform keyword search\n",
    "        # Extract keywords (simple implementation)\n",
    "        keywords = [word.lower() for word in query.split() if len(word) > 3]\n",
    "        if not keywords:\n",
    "            keywords = [query.lower()]\n",
    "        \n",
    "        # Build LIKE conditions for each keyword\n",
    "        like_conditions = []\n",
    "        for field in ['CLINICAL_NOTES', 'DESCRIPTION_OBSERVATIONS', 'DESCRIPTION_CONDITIONS', \n",
    "                     'DESCRIPTION_PROCEDURES', 'DESCRIPTION_MEDICATIONS']:\n",
    "            for keyword in keywords:\n",
    "                like_conditions.append(f\"{field} LIKE '%{keyword}%'\")\n",
    "        \n",
    "        where_clause = \" OR \".join(like_conditions)\n",
    "        \n",
    "        # Keyword search query\n",
    "        keyword_sql = text(f\"\"\"\n",
    "            SELECT \n",
    "                TOP {top_n * 2}\n",
    "                ENCOUNTER_ID,\n",
    "                CLINICAL_NOTES,\n",
    "                DESCRIPTION_OBSERVATIONS,\n",
    "                DESCRIPTION_CONDITIONS,\n",
    "                DESCRIPTION_PROCEDURES,\n",
    "                DESCRIPTION_MEDICATIONS,\n",
    "                (\n",
    "                    {\" + \".join([f\"(CASE WHEN {field} LIKE '%{keyword}%' THEN 1 ELSE 0 END)\" \n",
    "                                for field in ['CLINICAL_NOTES', 'DESCRIPTION_OBSERVATIONS', \n",
    "                                             'DESCRIPTION_CONDITIONS', 'DESCRIPTION_PROCEDURES', \n",
    "                                             'DESCRIPTION_MEDICATIONS']\n",
    "                                for keyword in keywords])}\n",
    "                ) AS keyword_score\n",
    "            FROM GenAI.encounters\n",
    "            WHERE {where_clause}\n",
    "            ORDER BY keyword_score DESC\n",
    "        \"\"\")\n",
    "        \n",
    "        keyword_results = conn.execute(keyword_sql).fetchall()\n",
    "    \n",
    "    # Step 3: Convert results to DataFrames\n",
    "    vector_df = pd.DataFrame(vector_results, columns=[\n",
    "        \"ENCOUNTER_ID\", \"CLINICAL_NOTES\", \"DESCRIPTION_OBSERVATIONS\", \n",
    "        \"DESCRIPTION_CONDITIONS\", \"DESCRIPTION_PROCEDURES\", \"DESCRIPTION_MEDICATIONS\",\n",
    "        \"sim_notes\", \"sim_obs\", \"sim_cond\", \"sim_proc\", \"sim_med\", \"vector_score\"\n",
    "    ])\n",
    "    \n",
    "    keyword_df = pd.DataFrame(keyword_results, columns=[\n",
    "        \"ENCOUNTER_ID\", \"CLINICAL_NOTES\", \"DESCRIPTION_OBSERVATIONS\", \n",
    "        \"DESCRIPTION_CONDITIONS\", \"DESCRIPTION_PROCEDURES\", \"DESCRIPTION_MEDICATIONS\",\n",
    "        \"keyword_score\"\n",
    "    ])\n",
    "    \n",
    "    # Step 4: Normalize scores to 0-1 range\n",
    "    if not vector_df.empty:\n",
    "        # UPDATED: Convert string to numeric values\n",
    "        vector_df['vector_score'] = pd.to_numeric(vector_df['vector_score'], errors='coerce')\n",
    "        max_vector_score = vector_df['vector_score'].max()\n",
    "        if pd.notnull(max_vector_score) and max_vector_score > 0:\n",
    "            vector_df['vector_score_norm'] = vector_df['vector_score'] / max_vector_score\n",
    "        else:\n",
    "            vector_df['vector_score_norm'] = vector_df['vector_score']\n",
    "    \n",
    "    if not keyword_df.empty:\n",
    "        # UPDATED: Convert string to numeric values\n",
    "        keyword_df['keyword_score'] = pd.to_numeric(keyword_df['keyword_score'], errors='coerce')\n",
    "        max_keyword_score = keyword_df['keyword_score'].max()\n",
    "        if pd.notnull(max_keyword_score) and max_keyword_score > 0:\n",
    "            keyword_df['keyword_score_norm'] = keyword_df['keyword_score'] / max_keyword_score\n",
    "        else:\n",
    "            keyword_df['keyword_score_norm'] = keyword_df['keyword_score']\n",
    "    \n",
    "    # Step 5: Merge results\n",
    "    # Start with all vector results\n",
    "    combined_results = vector_df.copy() if not vector_df.empty else pd.DataFrame()\n",
    "\n",
    "    # Add keyword score column (0 for entries only in vector results)\n",
    "    if not combined_results.empty:\n",
    "        combined_results['keyword_score'] = 0\n",
    "        combined_results['keyword_score_norm'] = 0\n",
    "\n",
    "    # Add keyword results not already in vector results\n",
    "    if not keyword_df.empty:\n",
    "        # Find keyword results not in vector results\n",
    "        if not combined_results.empty:\n",
    "            keyword_only = keyword_df[~keyword_df['ENCOUNTER_ID'].isin(combined_results['ENCOUNTER_ID'])].copy()  # Added .copy()\n",
    "        else:\n",
    "            keyword_only = keyword_df.copy()  # Added .copy()\n",
    "            \n",
    "        # Add vector score columns (0 for entries only in keyword results)\n",
    "        if not keyword_only.empty:\n",
    "            # FIX: Use .loc to avoid the SettingWithCopyWarning\n",
    "            for col in ['sim_notes', 'sim_obs', 'sim_cond', 'sim_proc', 'sim_med', 'vector_score', 'vector_score_norm']:\n",
    "                keyword_only.loc[:, col] = 0  # Changed to use .loc\n",
    "            \n",
    "            # Append to combined results\n",
    "            combined_results = pd.concat([combined_results, keyword_only])\n",
    "\n",
    "    # Step 6: Update scores for entries in both result sets\n",
    "    if not combined_results.empty and not keyword_df.empty:\n",
    "        # For each row in combined results that also exists in keyword results\n",
    "        for encounter_id in combined_results['ENCOUNTER_ID']:\n",
    "            keyword_match = keyword_df[keyword_df['ENCOUNTER_ID'] == encounter_id]\n",
    "            if not keyword_match.empty:\n",
    "                # UPDATED: Ensure values are numeric before assignment\n",
    "                combined_results.loc[combined_results['ENCOUNTER_ID'] == encounter_id, 'keyword_score'] = pd.to_numeric(keyword_match['keyword_score'].values[0], errors='coerce')\n",
    "                combined_results.loc[combined_results['ENCOUNTER_ID'] == encounter_id, 'keyword_score_norm'] = pd.to_numeric(keyword_match['keyword_score_norm'].values[0], errors='coerce')\n",
    "    \n",
    "    # Step 7: Calculate hybrid score\n",
    "    if not combined_results.empty:\n",
    "        # UPDATED: Ensure values are numeric before calculation\n",
    "        combined_results['vector_score_norm'] = pd.to_numeric(combined_results['vector_score_norm'], errors='coerce').fillna(0)\n",
    "        combined_results['keyword_score_norm'] = pd.to_numeric(combined_results['keyword_score_norm'], errors='coerce').fillna(0)\n",
    "        \n",
    "        combined_results['hybrid_score'] = (\n",
    "            combined_results['vector_score_norm'] * vector_weight + \n",
    "            combined_results['keyword_score_norm'] * keyword_weight\n",
    "        )\n",
    "        \n",
    "        # Sort by hybrid score\n",
    "        combined_results = combined_results.sort_values(by='hybrid_score', ascending=False)\n",
    "    \n",
    "    # Step 8: Return top N results\n",
    "    return combined_results.head(top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dd4735",
   "metadata": {},
   "source": [
    "Let's run a search for \"diabetes\" using the block below, which initially weighs the vector search at 0.7 and the keyword search at 0.3. What do you notice about the results? Inspect the results and note which encounters show up at the top of the list, and perhaps why they did so.\n",
    "\n",
    "After running that search, return to the code and adjust the `vector_weight` and `keyword_weight` values, perhaps inverting them. What differences do you notice in the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49834937",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"diabetes\"\n",
    "results_df = hybrid_search(\n",
    "    query=query,\n",
    "    engine=engine,\n",
    "    model=model,\n",
    "    top_n=5,\n",
    "    vector_weight=0.7,\n",
    "    keyword_weight=0.3\n",
    ")\n",
    "\n",
    "results_df[\"DESCRIPTION_OBSERVATIONS\"] = results_df[\"DESCRIPTION_OBSERVATIONS\"].str[:250]\n",
    "\n",
    "# Display the top 5 results\n",
    "print(f\"Hybrid Search Results for: '{query}'\")\n",
    "results_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1026f5d1",
   "metadata": {},
   "source": [
    "You may have noticed that by inverting the weights of vector and keyword search, you got different results. For example, by more heavily weighing keyword search in the query, most results will include the string \"diabetes\". When weighing semantic search more heavily, you might have noticed that the top results included phrases such as \"Insulin therapy,\" even if the word \"diabetes\" was not present.\n",
    "\n",
    "Run the block below to display all of the results, including each result's vector score and keyword score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2ab9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_hybrid_search():\n",
    "    \"\"\"Test the hybrid search functionality with a sample query.\"\"\"\n",
    "    from dotenv import load_dotenv\n",
    "    from sqlalchemy import create_engine\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    import os\n",
    "    from tabulate import tabulate  # Install with: pip install tabulate\n",
    "    import textwrap\n",
    "    from colorama import Fore, Style, init  # Install with: pip install colorama\n",
    "    \n",
    "    # Initialize colorama for colored terminal output\n",
    "    init(autoreset=True)\n",
    "    \n",
    "   \n",
    "    \n",
    "    # Test queries\n",
    "    test_queries = [\n",
    "        \"diabetes\",\n",
    "        \"diabetic\"\n",
    "    ]\n",
    "    \n",
    "    for query in test_queries:\n",
    "        print(f\"\\n\\n{Fore.CYAN}{'=' * 100}\")\n",
    "        print(f\"{Fore.CYAN}Hybrid Search Results for: {Fore.YELLOW}'{query}'\")\n",
    "        print(f\"{Fore.CYAN}{'=' * 100}\")\n",
    "        \n",
    "        # Perform hybrid search\n",
    "        results = hybrid_search(\n",
    "            query=query,\n",
    "            engine=engine,\n",
    "            model=model,\n",
    "            top_n=5,\n",
    "            vector_weight=0.7,\n",
    "            keyword_weight=0.3\n",
    "        )\n",
    "        \n",
    "        if results.empty:\n",
    "            print(f\"{Fore.RED}No results found.\")\n",
    "        else:\n",
    "            # Format results for display\n",
    "            display_data = []\n",
    "            \n",
    "            for index, row in results.iterrows():\n",
    "                # Truncate and format the clinical notes\n",
    "                notes_preview = textwrap.shorten(row['CLINICAL_NOTES'], width=80, placeholder=\"...\")\n",
    "                \n",
    "                # Format scores with appropriate precision\n",
    "                vector_score = f\"{float(row['vector_score']):.4f}\"\n",
    "                keyword_score = f\"{float(row['keyword_score']):.0f}\"\n",
    "                hybrid_score = f\"{float(row['hybrid_score']):.4f}\"\n",
    "                \n",
    "                display_data.append([\n",
    "                    row['ENCOUNTER_ID'],\n",
    "                    notes_preview,\n",
    "                    vector_score,\n",
    "                    keyword_score,\n",
    "                    hybrid_score\n",
    "                ])\n",
    "            \n",
    "            # Display results in a nicely formatted table\n",
    "            headers = [\n",
    "                f\"{Fore.GREEN}Encounter ID\", \n",
    "                f\"{Fore.GREEN}Clinical Notes Preview\", \n",
    "                f\"{Fore.GREEN}Vector Score\", \n",
    "                f\"{Fore.GREEN}Keyword Score\", \n",
    "                f\"{Fore.GREEN}Hybrid Score\"\n",
    "            ]\n",
    "            \n",
    "            print(tabulate(display_data, headers=headers, tablefmt=\"fancy_grid\"))\n",
    "            \n",
    "            # Print detailed information for the top result\n",
    "            if len(results) > 0:\n",
    "                top_result = results.iloc[0]\n",
    "                \n",
    "                print(f\"\\n{Fore.MAGENTA}Top Result Details:{Style.RESET_ALL}\")\n",
    "                print(f\"{Fore.MAGENTA}{'-' * 100}\")\n",
    "                \n",
    "                # Encounter details\n",
    "                print(f\"{Fore.YELLOW}Encounter ID:{Style.RESET_ALL} {top_result['ENCOUNTER_ID']}\")\n",
    "                print(f\"{Fore.YELLOW}Vector Score:{Style.RESET_ALL} {float(top_result['vector_score']):.4f}\")\n",
    "                print(f\"{Fore.YELLOW}Keyword Score:{Style.RESET_ALL} {float(top_result['keyword_score']):.0f}\")\n",
    "                print(f\"{Fore.YELLOW}Hybrid Score:{Style.RESET_ALL} {float(top_result['hybrid_score']):.4f}\")\n",
    "                \n",
    "                # Format clinical notes with proper wrapping\n",
    "                print(f\"\\n{Fore.YELLOW}Clinical Notes:{Style.RESET_ALL}\")\n",
    "                notes = top_result['CLINICAL_NOTES']\n",
    "                if len(notes) > 800:\n",
    "                    notes = notes[:800] + \"...\"\n",
    "                \n",
    "                # Wrap text for better readability\n",
    "                wrapped_notes = textwrap.fill(notes, width=100)\n",
    "                print(wrapped_notes)\n",
    "                \n",
    "                # Show observations if available\n",
    "                if top_result['DESCRIPTION_OBSERVATIONS']:\n",
    "                    print(f\"\\n{Fore.YELLOW}Observations:{Style.RESET_ALL}\")\n",
    "                    obs = top_result['DESCRIPTION_OBSERVATIONS']\n",
    "                    if len(obs) > 400:\n",
    "                        obs = obs[:400] + \"...\"\n",
    "                    print(textwrap.fill(obs, width=100))\n",
    "                \n",
    "                # Show conditions if available\n",
    "                if top_result['DESCRIPTION_CONDITIONS']:\n",
    "                    print(f\"\\n{Fore.YELLOW}Conditions:{Style.RESET_ALL}\")\n",
    "                    cond = top_result['DESCRIPTION_CONDITIONS']\n",
    "                    if len(cond) > 400:\n",
    "                        cond = cond[:400] + \"...\"\n",
    "                    print(textwrap.fill(cond, width=100))\n",
    "\n",
    "# Run the test function\n",
    "if __name__ == \"__main__\":\n",
    "    test_hybrid_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integration-section",
   "metadata": {},
   "source": [
    "## 🔄 Integration with Chat Application and Evaluation\n",
    "\n",
    "Now that you've explored different retrieval techniques, let's see how to integrate these improvements into your chat application and measure their impact using DeepEval.\n",
    "\n",
    "### Step 7: Applying Retrieval Improvements to Your Chat App\n",
    "\n",
    "The retrieval techniques you've learned can be integrated into your chat application through the shared RAG module (`rag_module.py`). This ensures that improvements you make here automatically benefit your chat application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rag-integration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our shared RAG module\n",
    "from rag_module import WorkshopRAG\n",
    "\n",
    "# Example: Create an enhanced RAG system with custom retrieval\n",
    "print(\"🔧 Demonstrating RAG module integration...\")\n",
    "\n",
    "# Initialize the RAG system\n",
    "rag_system = WorkshopRAG(\n",
    "    collection_name=\"case_reports\",\n",
    "    llm_model=\"gpt-4-turbo\",\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "# Test a query\n",
    "test_question = \"What are the symptoms of pregnancy complications?\"\n",
    "answer, contexts = rag_system.query(test_question)\n",
    "\n",
    "print(f\"\\n📝 Question: {test_question}\")\n",
    "print(f\"🤖 Answer: {answer[:200]}...\")\n",
    "print(f\"📄 Retrieved {len(contexts)} contexts\")\n",
    "\n",
    "print(\"\\n💡 To apply retrieval improvements:\")\n",
    "print(\"   1. Modify the query() method in rag_module.py\")\n",
    "print(\"   2. Implement weighted scoring, hybrid search, etc.\")\n",
    "print(\"   3. Both chat app and evaluation will use the improved retrieval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation-integration",
   "metadata": {},
   "source": [
    "### Step 8: Measuring Improvement with DeepEval\n",
    "\n",
    "After implementing retrieval improvements, you should measure their impact using the evaluation framework from Notebook 5.\n",
    "\n",
    "**🔄 Recommended Workflow:**\n",
    "\n",
    "1. **Baseline Measurement**: Run Notebook 5 (`5-TestFirstFramework.ipynb`) to get baseline metrics\n",
    "2. **Apply Improvements**: Modify `rag_module.py` with techniques from this notebook\n",
    "3. **Re-evaluate**: Run Notebook 5 again to measure improvement\n",
    "4. **Compare Results**: Analyze which changes improved performance\n",
    "\n",
    "**📊 Key Metrics to Watch:**\n",
    "- **Answer Relevancy**: Did better retrieval lead to more relevant answers?\n",
    "- **Contextual Relevancy**: Are the retrieved contexts more relevant?\n",
    "- **Faithfulness**: Are answers more faithful to the retrieved information?\n",
    "- **Contextual Recall**: Is the system finding more relevant information?\n",
    "\n",
    "**💡 Example Improvements to Test:**\n",
    "- Weighted scoring across multiple fields (notes, conditions, procedures)\n",
    "- Hybrid search combining vector and keyword search\n",
    "- Custom similarity thresholds\n",
    "- Multi-step retrieval strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluation-reminder",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🧪 Ready to measure your improvements!\")\n",
    "print(\"\\n📋 Next Steps:\")\n",
    "print(\"   1. Choose a retrieval improvement from this notebook\")\n",
    "print(\"   2. Implement it in rag_module.py\")\n",
    "print(\"   3. Test in the chat app (Chat3-GuardrailsAndHistory-Refactored.py)\")\n",
    "print(\"   4. Run evaluation (5-TestFirstFramework.ipynb)\")\n",
    "print(\"   5. Compare metrics to see if performance improved\")\n",
    "\n",
    "print(\"\\n🎯 This creates a complete feedback loop:\")\n",
    "print(\"   Experiment → Implement → Test → Evaluate → Improve\")\n",
    "\n",
    "print(\"\\n📈 Track these metrics across iterations:\")\n",
    "metrics = [\n",
    "    \"Answer Relevancy\",\n",
    "    \"Faithfulness\", \n",
    "    \"Contextual Relevancy\",\n",
    "    \"Contextual Recall\"\n",
    "]\n",
    "for metric in metrics:\n",
    "    print(f\"   • {metric}\")\n",
    "\n",
    "print(\"\\n🚀 Happy experimenting!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## 🎯 Conclusion\n",
    "\n",
    "You've now learned how to:\n",
    "\n",
    "✅ **Tune retrieval mechanisms** using various IRIS vector search techniques  \n",
    "✅ **Implement weighted scoring** across multiple vectorized fields  \n",
    "✅ **Use hybrid search** combining vector and keyword approaches  \n",
    "✅ **Integrate improvements** into your chat application via the shared RAG module  \n",
    "✅ **Measure impact** using DeepEval's comprehensive evaluation framework  \n",
    "\n",
    "**🔄 The Complete Workshop Loop:**\n",
    "1. **Build** your RAG system (Notebooks 1-4)\n",
    "2. **Evaluate** with test-first framework (Notebook 5)\n",
    "3. **Improve** retrieval mechanisms (Notebook 6)\n",
    "4. **Re-evaluate** to measure improvements (Back to Notebook 5)\n",
    "5. **Iterate** until you achieve desired performance\n",
    "\n",
    "This systematic approach ensures your RAG improvements are data-driven and measurable!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
