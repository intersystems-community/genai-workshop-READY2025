{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "682b0195",
   "metadata": {},
   "source": [
    "## 6. Tuning Your Retrieval Mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebae88ef",
   "metadata": {},
   "source": [
    "Let's pivot to a more complex data set for the final two sections of this workshop.\n",
    "\n",
    "You're about to explore how we can enhance the way we retrieve relevant patient data from a medical dataset of patient encounters using various techniques. You will start by running a basic vector search in InterSystems IRIS, similar to earlier sections. Then you'll refine your results with advanced methods like weighted scoring and hybrid search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3202ca8a",
   "metadata": {},
   "source": [
    "### InterSystems IRIS Vector Search: A Recap\n",
    "To recap, InterSystems IRIS Vector Search allows us to store and query high-dimensional vector embeddings within a relational database. These embeddings represent unstructured data like clinical notes as numerical vectors, enabling semantic similarity comparisons. This means we can find patient encounters that are contextually similar to a query, using SQL operations enhanced by vectors.\n",
    "\n",
    "By integrating these capabilities into standard SQL operations, InterSystems IRIS transforms your relational database into a high-performance hybrid vector database ready to support next-generation AI applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822ddf82",
   "metadata": {},
   "source": [
    "### Step 1: Connecting to InterSystems IRIS and Viewing the Dataset\n",
    "Let's start by connecting to the InterSystems IRIS database to access our medical dataset.\n",
    "\n",
    "This new data set includes ~1,500 patient encounters, each with structured and coded medical data. With each encounter, however, is also a generated clinical summary note that provides more context about the patient. This might include things such as their commuting situation, their mood during the encounter, or other information not easily categorized into a structured encounter record. They are, however, still relatively lean and simple clinician notes.\n",
    "\n",
    "Run the block of code below to initiate a connection to InterSystems IRIS and view a snippet of this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b612b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "username = '_SYSTEM'\n",
    "password = 'SYS'\n",
    "hostname = 'IRIS'\n",
    "port = 1972\n",
    "namespace = 'IRISAPP'\n",
    "CONNECTION_STRING = f\"iris://{username}:{password}@{hostname}:{port}/{namespace}\"\n",
    "engine = create_engine(CONNECTION_STRING)\n",
    "\n",
    "df = pd.read_sql(\"SELECT * FROM GenAI.Encounters\", engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16017fd7",
   "metadata": {},
   "source": [
    "Notice that in addition to structured data—such as codes, costs, and standardized descriptions of the encounters—there are also columns with unstructured observations and notes, and accompanying vector embeddings. These vector embeddings will help a generative AI application retrieve relevant chunks of data from this set of patient encounters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d31ec47",
   "metadata": {},
   "source": [
    "### Step 2: Running a Simple Vector Search\n",
    "In this step, we’ll execute a basic vector search to find patient encounters similar to a query input.\n",
    "\n",
    "A simple vector search demonstrates how InterSystems IRIS compares embeddings to find semantically relevant results. For example, querying for something like \"Headache\" would return encounters with similar clinical notes, even if the exact words differ. This is the starting point for understanding retrieval based on meaning rather than keywords\n",
    "\n",
    "First, run the following line of code to select the sentence transformer model that will be used to create an embedding from your search term. The embedding model you use to embed your search queries should be compatible with the model used to create embeddings in your data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d6d3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01801dba",
   "metadata": {},
   "source": [
    "Run the next module, optionally replacing \"Headache\" with a search term of your choice. This module will create and print an embedding for the search term you have entered. You will see that the embedding, even for a simple search term, consists of 384 dimensions—the number of dimensions in the FastEmbed embeddings model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f746e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_search = \"Headache\"\n",
    "search_vector = model.encode(note_search, normalize_embeddings=True).tolist() # Convert search phrase into a vector\n",
    "print(search_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c81acfe",
   "metadata": {},
   "source": [
    "Now let's run a vector search against our CLINICAL_NOTES field using your search term. With the code below, you will retrieve the top three chunks from the CLINICAL_NOTES field in your data set that are deemed most similar to the search term you provided. The results will be displayed in a Pandas DataFrame for easy viewing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c76093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "vector_str = \",\".join(str(x) for x in search_vector)\n",
    "## print(vector_str)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    with conn.begin():\n",
    "        sql = text(\"\"\"\n",
    "            SELECT TOP 3 ENCOUNTER_ID, CLINICAL_NOTES\n",
    "            FROM GenAI.encounters\n",
    "            ORDER BY VECTOR_DOT_PRODUCT(CLINICAL_NOTES_Vector, TO_VECTOR(:search_vector)) DESC\n",
    "        \"\"\")\n",
    "        results = conn.execute(sql, {\"search_vector\": vector_str}).fetchall()\n",
    "\n",
    "# Display results\n",
    "df = pd.DataFrame(results)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64968f8",
   "metadata": {},
   "source": [
    "### Step 3: Searching across multiple vectorized fields\n",
    "Let's now consider that you may want to search across more than just your CLINICAL_NOTES field. To improve relevance, we’ll break down similarity across different data categories (notes, observations, etc.) to see which aspects contribute most to the match. This will help us fine-tune our search.\n",
    "\n",
    "In the block below, you will notice that similarities are being calculated between your search term and all five vectorized fields in the data set. Then, the results are being ordered by the greatest similarity match.\n",
    "\n",
    "In the result set that follows, explore the similarity scores provided. Sometimes one field provides a particularly good match, while others do not.\n",
    "\n",
    "Enter whatever search term you would like in the *note_search* variable. Feel free to play around with multiple searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc1549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_search = \"Knee pain\"\n",
    "search_vector = model.encode(note_search, normalize_embeddings=True).tolist() # Convert search phrase into a vector\n",
    "## print(search_vector)\n",
    "\n",
    "vector_str = \",\".join(str(x) for x in search_vector) \n",
    "\n",
    "with engine.connect() as conn:\n",
    "    with conn.begin():\n",
    "        sql = text(\"\"\"\n",
    "            SELECT TOP 5\n",
    "                ENCOUNTER_ID,\n",
    "                CLINICAL_NOTES,\n",
    "                DESCRIPTION_OBSERVATIONS,\n",
    "                DESCRIPTION_CONDITIONS,\n",
    "                DESCRIPTION_PROCEDURES,\n",
    "                DESCRIPTION_MEDICATIONS,\n",
    "                VECTOR_DOT_PRODUCT (CLINICAL_NOTES_Vector, TO_VECTOR(:search_vector))\n",
    "                    AS sim_notes,\n",
    "                VECTOR_DOT_PRODUCT(DESCRIPTION_OBSERVATIONS_Vector, TO_VECTOR(:search_vector))\n",
    "                    AS sim_obs,\n",
    "                VECTOR_DOT_PRODUCT(DESCRIPTION_CONDITIONS_Vector,   TO_VECTOR(:search_vector))\n",
    "                    AS sim_cond,\n",
    "                VECTOR_DOT_PRODUCT(DESCRIPTION_PROCEDURES_Vector,   TO_VECTOR(:search_vector))\n",
    "                    AS sim_proc,\n",
    "                VECTOR_DOT_PRODUCT(DESCRIPTION_MEDICATIONS_Vector,  TO_VECTOR(:search_vector))\n",
    "                    AS sim_med\n",
    "            FROM GenAI.encounters\n",
    "            ORDER BY GREATEST(\n",
    "                VECTOR_DOT_PRODUCT(CLINICAL_NOTES_Vector,           TO_VECTOR(:search_vector)),\n",
    "                VECTOR_DOT_PRODUCT(DESCRIPTION_OBSERVATIONS_Vector, TO_VECTOR(:search_vector)),\n",
    "                VECTOR_DOT_PRODUCT(DESCRIPTION_CONDITIONS_Vector,   TO_VECTOR(:search_vector)),\n",
    "                VECTOR_DOT_PRODUCT(DESCRIPTION_PROCEDURES_Vector,   TO_VECTOR(:search_vector)),\n",
    "                VECTOR_DOT_PRODUCT(DESCRIPTION_MEDICATIONS_Vector,  TO_VECTOR(:search_vector))\n",
    ") DESC\n",
    "\n",
    "        \"\"\")\n",
    "        results = conn.execute(sql, {\"search_vector\": vector_str}).fetchall()\n",
    "df = pd.DataFrame(results, columns=[\n",
    "    \"ENCOUNTER_ID\",\n",
    "    \"CLINICAL_NOTES\", \"DESCRIPTION_OBSERVATIONS\", \"DESCRIPTION_CONDITIONS\",\n",
    "    \"DESCRIPTION_PROCEDURES\", \"DESCRIPTION_MEDICATIONS\",\n",
    "    \"sim_notes\",\n",
    "    \"sim_obs\",\n",
    "    \"sim_cond\",\n",
    "    \"sim_proc\",\n",
    "    \"sim_med\"\n",
    "])\n",
    "df[\"DESCRIPTION_OBSERVATIONS\"] = df[\"DESCRIPTION_OBSERVATIONS\"].str[:250]\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4dfba4",
   "metadata": {},
   "source": [
    "Looking at the results (if you kept the standard search phrase of \"knee pain\"), notice a few things:\n",
    "- ENCOUNTER_ID 1260 has a higher sim_proc score (0.235474) compared to other categories, suggesting the procedures described are more similar to the query\n",
    "- ENCOUNTER_ID 910 shows higher scores across *sim_notes*, *sim_cond*, and *sim_med* (all 0.235365), indicating broader relevance.\n",
    "\n",
    "This breakdown reveals varying contributions from different data types, but it’s not yet a unified ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021dc4cd",
   "metadata": {},
   "source": [
    "In the previous block, we used Vector Dot Product to determine similarity. So, what's the difference between using VECTOR DOT PRODUCT and COSINE SIMILARITY?\n",
    "\n",
    "- Vector Dot Product: Faster computation but sensitive to vector magnitude\n",
    "- Cosine Similarity: Magnitude-independent but slightly more computation\n",
    "\n",
    "Try running the block below to conduct the same search using Cosine Similarity instead of Vector Dot Product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09081c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_search = \"Knee pain\"\n",
    "search_vector = model.encode(note_search, normalize_embeddings=True).tolist() # Convert search phrase into a vector\n",
    "## print(search_vector)\n",
    "\n",
    "vector_str = \",\".join(str(x) for x in search_vector) \n",
    "\n",
    "with engine.connect() as conn:\n",
    "    with conn.begin():\n",
    "        sql = text(\"\"\"\n",
    "            SELECT TOP 5\n",
    "                ENCOUNTER_ID,\n",
    "                CLINICAL_NOTES,\n",
    "                DESCRIPTION_OBSERVATIONS,\n",
    "                DESCRIPTION_CONDITIONS,\n",
    "                DESCRIPTION_PROCEDURES,\n",
    "                DESCRIPTION_MEDICATIONS,\n",
    "                VECTOR_COSINE (CLINICAL_NOTES_Vector, TO_VECTOR(:search_vector))\n",
    "                    AS sim_notes,\n",
    "                VECTOR_COSINE (DESCRIPTION_OBSERVATIONS_Vector, TO_VECTOR(:search_vector))\n",
    "                    AS sim_obs,\n",
    "                VECTOR_COSINE (DESCRIPTION_CONDITIONS_Vector,   TO_VECTOR(:search_vector))\n",
    "                    AS sim_cond,\n",
    "                VECTOR_COSINE (DESCRIPTION_PROCEDURES_Vector,   TO_VECTOR(:search_vector))\n",
    "                    AS sim_proc,\n",
    "                VECTOR_COSINE(DESCRIPTION_MEDICATIONS_Vector,  TO_VECTOR(:search_vector))\n",
    "                    AS sim_med\n",
    "            FROM GenAI.encounters\n",
    "            ORDER BY GREATEST(\n",
    "                VECTOR_COSINE (CLINICAL_NOTES_Vector,           TO_VECTOR(:search_vector)),\n",
    "                VECTOR_COSINE (DESCRIPTION_OBSERVATIONS_Vector, TO_VECTOR(:search_vector)),\n",
    "                VECTOR_COSINE (DESCRIPTION_CONDITIONS_Vector,   TO_VECTOR(:search_vector)),\n",
    "                VECTOR_COSINE (DESCRIPTION_PROCEDURES_Vector,   TO_VECTOR(:search_vector)),\n",
    "                VECTOR_COSINE (DESCRIPTION_MEDICATIONS_Vector,  TO_VECTOR(:search_vector))\n",
    ") DESC\n",
    "\n",
    "        \"\"\")\n",
    "        results = conn.execute(sql, {\"search_vector\": vector_str}).fetchall()\n",
    "df = pd.DataFrame(results, columns=[\n",
    "    \"ENCOUNTER_ID\",\n",
    "    \"CLINICAL_NOTES\", \"DESCRIPTION_OBSERVATIONS\", \"DESCRIPTION_CONDITIONS\",\n",
    "    \"DESCRIPTION_PROCEDURES\", \"DESCRIPTION_MEDICATIONS\",\n",
    "    \"sim_notes\",\n",
    "    \"sim_obs\",\n",
    "    \"sim_cond\",\n",
    "    \"sim_proc\",\n",
    "    \"sim_med\"\n",
    "])\n",
    "df[\"DESCRIPTION_OBSERVATIONS\"] = df[\"DESCRIPTION_OBSERVATIONS\"].str[:250]\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faba341",
   "metadata": {},
   "source": [
    "Notice that the queries using VECTOR_DOT_PRODUCT and VECTOR_COSINE produce the same results. This is actually expected when working with normalized embeddings.\n",
    "\n",
    "Why are the results the same? The key is in the embedding generation:\n",
    "\n",
    "`search_vector = model.encode(note_search, normalize_embeddings=True).tolist()`\n",
    "\n",
    "When you set `normalize_embeddings=True`, your model is creating unit vectors (vectors with length 1). With normalized vectors, the dot product is mathematically equivalent to cosine similarity.\n",
    "\n",
    "In the hybrid search function later, we will be using cosine similarity with normalized vectors, which is a common best practice for semantic search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcac455",
   "metadata": {},
   "source": [
    "### Implementing Weight Adjustments for Multiple Vector Fields\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c43d29",
   "metadata": {},
   "source": [
    "Perhaps you don't simply want a generic search across several vector fields; perhaps you want to use certain weights to more heavily factor one field over another. Let's explore this concept.\n",
    "\n",
    "Run the block below to set weights, in this case weighing observations (sim_obs) and notes (sim_notes) a bit higher than other fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeba311",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'sim_notes': 0.25,\n",
    "    'sim_obs': 0.35,\n",
    "    'sim_cond': 0.1,\n",
    "    'sim_proc': 0.2,\n",
    "    'sim_med': 0.1\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e747757",
   "metadata": {},
   "source": [
    "Now let's adjust the SQL query to multiply each similarity score by its corresponding weight, then sum them up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff8d3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_search = \"diabetes\"\n",
    "search_vector = model.encode(note_search, normalize_embeddings=True).tolist()  # Convert search phrase into a vector\n",
    "vector_str = \",\".join(str(x) for x in search_vector)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    with conn.begin():\n",
    "        sql = text(f\"\"\"\n",
    "            SELECT TOP 5\n",
    "                ENCOUNTER_ID,\n",
    "                CLINICAL_NOTES,\n",
    "                DESCRIPTION_OBSERVATIONS,\n",
    "                DESCRIPTION_CONDITIONS,\n",
    "                DESCRIPTION_PROCEDURES,\n",
    "                DESCRIPTION_MEDICATIONS,\n",
    "                sim_notes,\n",
    "                sim_obs,\n",
    "                sim_cond,\n",
    "                sim_proc,\n",
    "                sim_med,\n",
    "                (\n",
    "                    sim_notes * {weights['sim_notes']} +\n",
    "                    sim_obs * {weights['sim_obs']} +\n",
    "                    sim_cond * {weights['sim_cond']} +\n",
    "                    sim_proc * {weights['sim_proc']} +\n",
    "                    sim_med * {weights['sim_med']}\n",
    "                ) AS weighted_sim\n",
    "            FROM (\n",
    "                SELECT\n",
    "                    ENCOUNTER_ID,\n",
    "                    CLINICAL_NOTES,\n",
    "                    DESCRIPTION_OBSERVATIONS,\n",
    "                    DESCRIPTION_CONDITIONS,\n",
    "                    DESCRIPTION_PROCEDURES,\n",
    "                    DESCRIPTION_MEDICATIONS,\n",
    "                    VECTOR_DOT_PRODUCT(CLINICAL_NOTES_Vector, TO_VECTOR(:search_vector)) AS sim_notes,\n",
    "                    VECTOR_DOT_PRODUCT(DESCRIPTION_OBSERVATIONS_Vector, TO_VECTOR(:search_vector)) AS sim_obs,\n",
    "                    VECTOR_DOT_PRODUCT(DESCRIPTION_CONDITIONS_Vector, TO_VECTOR(:search_vector)) AS sim_cond,\n",
    "                    VECTOR_DOT_PRODUCT(DESCRIPTION_PROCEDURES_Vector, TO_VECTOR(:search_vector)) AS sim_proc,\n",
    "                    VECTOR_DOT_PRODUCT(DESCRIPTION_MEDICATIONS_Vector, TO_VECTOR(:search_vector)) AS sim_med\n",
    "                FROM GenAI.encounters\n",
    "            ) AS subquery\n",
    "            ORDER BY weighted_sim DESC\n",
    "        \"\"\")\n",
    "        results = conn.execute(sql, {\"search_vector\": vector_str}).fetchall()\n",
    "\n",
    "df = pd.DataFrame(results, columns=[\n",
    "    \"ENCOUNTER_ID\",\n",
    "    \"CLINICAL_NOTES\", \"DESCRIPTION_OBSERVATIONS\", \"DESCRIPTION_CONDITIONS\",\n",
    "    \"DESCRIPTION_PROCEDURES\", \"DESCRIPTION_MEDICATIONS\",\n",
    "    \"sim_notes\",\n",
    "    \"sim_obs\",\n",
    "    \"sim_cond\",\n",
    "    \"sim_proc\",\n",
    "    \"sim_med\",\n",
    "    \"weighted_sim\"\n",
    "])\n",
    "df[\"DESCRIPTION_OBSERVATIONS\"] = df[\"DESCRIPTION_OBSERVATIONS\"].str[:250]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b56fb1",
   "metadata": {},
   "source": [
    "## Hybrid Search\n",
    "You can combine keyword-based search with vector-based search for more comprehensive results. For example, you can use a text search on the `note` field and combine it with the vector search for the same phrase.\n",
    "\n",
    "The hybrid search approach combines the strengths of both vector-based semantic search and traditional keyword search, which can provide more relevant results than either method alone. Vector search is good at understanding semantic meaning, while keyword search can catch exact matches that might be missed by the embedding model.\n",
    "\n",
    "You can adjust the `vector_weight` and `keyword_weight` parameters to fine-tune the balance between semantic similarity and keyword matching based on your specific use case.\n",
    "\n",
    "The block below is long; this block defines a full function for hybrid search. Feel free to inspect it, or simply run the module and proceed to the next block, where we'll experiment with `vector_weight` and `keyword_weight`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8779cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_search(query, engine, model, top_n=5, vector_weight=0.7, keyword_weight=0.3):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - query: Search query string\n",
    "    - engine: SQLAlchemy engine with connection to InterSystems IRIS\n",
    "    - model: model for embeddings\n",
    "    - top_n: Number of results to return\n",
    "    - vector_weight: Weight for vector search results (0.0 to 1.0)\n",
    "    - keyword_weight: Weight for keyword search results (0.0 to 1.0)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Perform vector search\n",
    "    search_vector = model.encode(query, normalize_embeddings=True).tolist()\n",
    "    vector_str = \",\".join(str(x) for x in search_vector)\n",
    "    \n",
    "    with engine.connect() as conn:\n",
    "        vector_sql = text(f\"\"\"\n",
    "            SELECT \n",
    "                TOP {top_n * 2}\n",
    "                ENCOUNTER_ID,\n",
    "                CLINICAL_NOTES,\n",
    "                DESCRIPTION_OBSERVATIONS,\n",
    "                DESCRIPTION_CONDITIONS,\n",
    "                DESCRIPTION_PROCEDURES,\n",
    "                DESCRIPTION_MEDICATIONS,\n",
    "                VECTOR_COSINE(CLINICAL_NOTES_Vector, TO_VECTOR(:search_vector)) AS sim_notes,\n",
    "                VECTOR_COSINE(DESCRIPTION_OBSERVATIONS_Vector, TO_VECTOR(:search_vector)) AS sim_obs,\n",
    "                VECTOR_COSINE(DESCRIPTION_CONDITIONS_Vector, TO_VECTOR(:search_vector)) AS sim_cond,\n",
    "                VECTOR_COSINE(DESCRIPTION_PROCEDURES_Vector, TO_VECTOR(:search_vector)) AS sim_proc,\n",
    "                VECTOR_COSINE(DESCRIPTION_MEDICATIONS_Vector, TO_VECTOR(:search_vector)) AS sim_med,\n",
    "                (\n",
    "                    VECTOR_COSINE(CLINICAL_NOTES_Vector, TO_VECTOR(:search_vector)) * {weights['sim_notes']} +\n",
    "                    VECTOR_COSINE(DESCRIPTION_OBSERVATIONS_Vector, TO_VECTOR(:search_vector)) * {weights['sim_obs']} +\n",
    "                    VECTOR_COSINE(DESCRIPTION_CONDITIONS_Vector, TO_VECTOR(:search_vector)) * {weights['sim_cond']} +\n",
    "                    VECTOR_COSINE(DESCRIPTION_PROCEDURES_Vector, TO_VECTOR(:search_vector)) * {weights['sim_proc']} +\n",
    "                    VECTOR_COSINE(DESCRIPTION_MEDICATIONS_Vector, TO_VECTOR(:search_vector)) * {weights['sim_med']}\n",
    "                ) AS vector_score\n",
    "            FROM GenAI.encounters\n",
    "            ORDER BY vector_score DESC\n",
    "        \"\"\")\n",
    "        \n",
    "        vector_results = conn.execute(vector_sql, {\"search_vector\": vector_str}).fetchall()\n",
    "        \n",
    "        # Step 2: Perform keyword search\n",
    "        # Extract keywords (simple implementation)\n",
    "        keywords = [word.lower() for word in query.split() if len(word) > 3]\n",
    "        if not keywords:\n",
    "            keywords = [query.lower()]\n",
    "        \n",
    "        # Build LIKE conditions for each keyword\n",
    "        like_conditions = []\n",
    "        for field in ['CLINICAL_NOTES', 'DESCRIPTION_OBSERVATIONS', 'DESCRIPTION_CONDITIONS', \n",
    "                     'DESCRIPTION_PROCEDURES', 'DESCRIPTION_MEDICATIONS']:\n",
    "            for keyword in keywords:\n",
    "                like_conditions.append(f\"{field} LIKE '%{keyword}%'\")\n",
    "        \n",
    "        where_clause = \" OR \".join(like_conditions)\n",
    "        \n",
    "        # Keyword search query\n",
    "        keyword_sql = text(f\"\"\"\n",
    "            SELECT \n",
    "                TOP {top_n * 2}\n",
    "                ENCOUNTER_ID,\n",
    "                CLINICAL_NOTES,\n",
    "                DESCRIPTION_OBSERVATIONS,\n",
    "                DESCRIPTION_CONDITIONS,\n",
    "                DESCRIPTION_PROCEDURES,\n",
    "                DESCRIPTION_MEDICATIONS,\n",
    "                (\n",
    "                    {\" + \".join([f\"(CASE WHEN {field} LIKE '%{keyword}%' THEN 1 ELSE 0 END)\" \n",
    "                                for field in ['CLINICAL_NOTES', 'DESCRIPTION_OBSERVATIONS', \n",
    "                                             'DESCRIPTION_CONDITIONS', 'DESCRIPTION_PROCEDURES', \n",
    "                                             'DESCRIPTION_MEDICATIONS']\n",
    "                                for keyword in keywords])}\n",
    "                ) AS keyword_score\n",
    "            FROM GenAI.encounters\n",
    "            WHERE {where_clause}\n",
    "            ORDER BY keyword_score DESC\n",
    "        \"\"\")\n",
    "        \n",
    "        keyword_results = conn.execute(keyword_sql).fetchall()\n",
    "    \n",
    "    # Step 3: Convert results to DataFrames\n",
    "    vector_df = pd.DataFrame(vector_results, columns=[\n",
    "        \"ENCOUNTER_ID\", \"CLINICAL_NOTES\", \"DESCRIPTION_OBSERVATIONS\", \n",
    "        \"DESCRIPTION_CONDITIONS\", \"DESCRIPTION_PROCEDURES\", \"DESCRIPTION_MEDICATIONS\",\n",
    "        \"sim_notes\", \"sim_obs\", \"sim_cond\", \"sim_proc\", \"sim_med\", \"vector_score\"\n",
    "    ])\n",
    "    \n",
    "    keyword_df = pd.DataFrame(keyword_results, columns=[\n",
    "        \"ENCOUNTER_ID\", \"CLINICAL_NOTES\", \"DESCRIPTION_OBSERVATIONS\", \n",
    "        \"DESCRIPTION_CONDITIONS\", \"DESCRIPTION_PROCEDURES\", \"DESCRIPTION_MEDICATIONS\",\n",
    "        \"keyword_score\"\n",
    "    ])\n",
    "    \n",
    "    # Step 4: Normalize scores to 0-1 range\n",
    "    if not vector_df.empty:\n",
    "        # UPDATED: Convert string to numeric values\n",
    "        vector_df['vector_score'] = pd.to_numeric(vector_df['vector_score'], errors='coerce')\n",
    "        max_vector_score = vector_df['vector_score'].max()\n",
    "        if pd.notnull(max_vector_score) and max_vector_score > 0:\n",
    "            vector_df['vector_score_norm'] = vector_df['vector_score'] / max_vector_score\n",
    "        else:\n",
    "            vector_df['vector_score_norm'] = vector_df['vector_score']\n",
    "    \n",
    "    if not keyword_df.empty:\n",
    "        # UPDATED: Convert string to numeric values\n",
    "        keyword_df['keyword_score'] = pd.to_numeric(keyword_df['keyword_score'], errors='coerce')\n",
    "        max_keyword_score = keyword_df['keyword_score'].max()\n",
    "        if pd.notnull(max_keyword_score) and max_keyword_score > 0:\n",
    "            keyword_df['keyword_score_norm'] = keyword_df['keyword_score'] / max_keyword_score\n",
    "        else:\n",
    "            keyword_df['keyword_score_norm'] = keyword_df['keyword_score']\n",
    "    \n",
    "    # Step 5: Merge results\n",
    "    # Start with all vector results\n",
    "    combined_results = vector_df.copy() if not vector_df.empty else pd.DataFrame()\n",
    "\n",
    "    # Add keyword score column (0 for entries only in vector results)\n",
    "    if not combined_results.empty:\n",
    "        combined_results['keyword_score'] = 0\n",
    "        combined_results['keyword_score_norm'] = 0\n",
    "\n",
    "    # Add keyword results not already in vector results\n",
    "    if not keyword_df.empty:\n",
    "        # Find keyword results not in vector results\n",
    "        if not combined_results.empty:\n",
    "            keyword_only = keyword_df[~keyword_df['ENCOUNTER_ID'].isin(combined_results['ENCOUNTER_ID'])].copy()  # Added .copy()\n",
    "        else:\n",
    "            keyword_only = keyword_df.copy()  # Added .copy()\n",
    "            \n",
    "        # Add vector score columns (0 for entries only in keyword results)\n",
    "        if not keyword_only.empty:\n",
    "            # FIX: Use .loc to avoid the SettingWithCopyWarning\n",
    "            for col in ['sim_notes', 'sim_obs', 'sim_cond', 'sim_proc', 'sim_med', 'vector_score', 'vector_score_norm']:\n",
    "                keyword_only.loc[:, col] = 0  # Changed to use .loc\n",
    "            \n",
    "            # Append to combined results\n",
    "            combined_results = pd.concat([combined_results, keyword_only])\n",
    "\n",
    "    # Step 6: Update scores for entries in both result sets\n",
    "    if not combined_results.empty and not keyword_df.empty:\n",
    "        # For each row in combined results that also exists in keyword results\n",
    "        for encounter_id in combined_results['ENCOUNTER_ID']:\n",
    "            keyword_match = keyword_df[keyword_df['ENCOUNTER_ID'] == encounter_id]\n",
    "            if not keyword_match.empty:\n",
    "                # UPDATED: Ensure values are numeric before assignment\n",
    "                combined_results.loc[combined_results['ENCOUNTER_ID'] == encounter_id, 'keyword_score'] = pd.to_numeric(keyword_match['keyword_score'].values[0], errors='coerce')\n",
    "                combined_results.loc[combined_results['ENCOUNTER_ID'] == encounter_id, 'keyword_score_norm'] = pd.to_numeric(keyword_match['keyword_score_norm'].values[0], errors='coerce')\n",
    "    \n",
    "    # Step 7: Calculate hybrid score\n",
    "    if not combined_results.empty:\n",
    "        # UPDATED: Ensure values are numeric before calculation\n",
    "        combined_results['vector_score_norm'] = pd.to_numeric(combined_results['vector_score_norm'], errors='coerce').fillna(0)\n",
    "        combined_results['keyword_score_norm'] = pd.to_numeric(combined_results['keyword_score_norm'], errors='coerce').fillna(0)\n",
    "        \n",
    "        combined_results['hybrid_score'] = (\n",
    "            combined_results['vector_score_norm'] * vector_weight + \n",
    "            combined_results['keyword_score_norm'] * keyword_weight\n",
    "        )\n",
    "        \n",
    "        # Sort by hybrid score\n",
    "        combined_results = combined_results.sort_values(by='hybrid_score', ascending=False)\n",
    "    \n",
    "    # Step 8: Return top N results\n",
    "    return combined_results.head(top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dd4735",
   "metadata": {},
   "source": [
    "Let's run a search for \"diabetes\" using the block below, which initially weighs the vector search at 0.7 and the keyword search at 0.3. What do you notice about the results? Inspect the results and note which encounters show up at the top of the list, and perhaps why they did so.\n",
    "\n",
    "After running that search, return to the code and adjust the `vector_weight` and `keyword_weight` values, perhaps inverting them. What differences do you notice in the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49834937",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"diabetes\"\n",
    "results_df = hybrid_search(\n",
    "    query=query,\n",
    "    engine=engine,\n",
    "    model=model,\n",
    "    top_n=5,\n",
    "    vector_weight=0.7,\n",
    "    keyword_weight=0.3\n",
    ")\n",
    "\n",
    "results_df[\"DESCRIPTION_OBSERVATIONS\"] = results_df[\"DESCRIPTION_OBSERVATIONS\"].str[:250]\n",
    "\n",
    "# Display the top 5 results\n",
    "print(f\"Hybrid Search Results for: '{query}'\")\n",
    "results_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2ab9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_hybrid_search():\n",
    "    \"\"\"Test the hybrid search functionality with a sample query.\"\"\"\n",
    "    from dotenv import load_dotenv\n",
    "    from sqlalchemy import create_engine\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    import os\n",
    "    from tabulate import tabulate  # Install with: pip install tabulate\n",
    "    import textwrap\n",
    "    from colorama import Fore, Style, init  # Install with: pip install colorama\n",
    "    \n",
    "    # Initialize colorama for colored terminal output\n",
    "    init(autoreset=True)\n",
    "    \n",
    "   \n",
    "    \n",
    "    # Test queries\n",
    "    test_queries = [\n",
    "        \"diabetes\",\n",
    "        \"diabetic\"\n",
    "    ]\n",
    "    \n",
    "    for query in test_queries:\n",
    "        print(f\"\\n\\n{Fore.CYAN}{'=' * 100}\")\n",
    "        print(f\"{Fore.CYAN}Hybrid Search Results for: {Fore.YELLOW}'{query}'\")\n",
    "        print(f\"{Fore.CYAN}{'=' * 100}\")\n",
    "        \n",
    "        # Perform hybrid search\n",
    "        results = hybrid_search(\n",
    "            query=query,\n",
    "            engine=engine,\n",
    "            model=model,\n",
    "            top_n=5,\n",
    "            vector_weight=0.7,\n",
    "            keyword_weight=0.3\n",
    "        )\n",
    "        \n",
    "        if results.empty:\n",
    "            print(f\"{Fore.RED}No results found.\")\n",
    "        else:\n",
    "            # Format results for display\n",
    "            display_data = []\n",
    "            \n",
    "            for index, row in results.iterrows():\n",
    "                # Truncate and format the clinical notes\n",
    "                notes_preview = textwrap.shorten(row['CLINICAL_NOTES'], width=80, placeholder=\"...\")\n",
    "                \n",
    "                # Format scores with appropriate precision\n",
    "                vector_score = f\"{float(row['vector_score']):.4f}\"\n",
    "                keyword_score = f\"{float(row['keyword_score']):.0f}\"\n",
    "                hybrid_score = f\"{float(row['hybrid_score']):.4f}\"\n",
    "                \n",
    "                display_data.append([\n",
    "                    row['ENCOUNTER_ID'],\n",
    "                    notes_preview,\n",
    "                    vector_score,\n",
    "                    keyword_score,\n",
    "                    hybrid_score\n",
    "                ])\n",
    "            \n",
    "            # Display results in a nicely formatted table\n",
    "            headers = [\n",
    "                f\"{Fore.GREEN}Encounter ID\", \n",
    "                f\"{Fore.GREEN}Clinical Notes Preview\", \n",
    "                f\"{Fore.GREEN}Vector Score\", \n",
    "                f\"{Fore.GREEN}Keyword Score\", \n",
    "                f\"{Fore.GREEN}Hybrid Score\"\n",
    "            ]\n",
    "            \n",
    "            print(tabulate(display_data, headers=headers, tablefmt=\"fancy_grid\"))\n",
    "            \n",
    "            # Print detailed information for the top result\n",
    "            if len(results) > 0:\n",
    "                top_result = results.iloc[0]\n",
    "                \n",
    "                print(f\"\\n{Fore.MAGENTA}Top Result Details:{Style.RESET_ALL}\")\n",
    "                print(f\"{Fore.MAGENTA}{'-' * 100}\")\n",
    "                \n",
    "                # Encounter details\n",
    "                print(f\"{Fore.YELLOW}Encounter ID:{Style.RESET_ALL} {top_result['ENCOUNTER_ID']}\")\n",
    "                print(f\"{Fore.YELLOW}Vector Score:{Style.RESET_ALL} {float(top_result['vector_score']):.4f}\")\n",
    "                print(f\"{Fore.YELLOW}Keyword Score:{Style.RESET_ALL} {float(top_result['keyword_score']):.0f}\")\n",
    "                print(f\"{Fore.YELLOW}Hybrid Score:{Style.RESET_ALL} {float(top_result['hybrid_score']):.4f}\")\n",
    "                \n",
    "                # Format clinical notes with proper wrapping\n",
    "                print(f\"\\n{Fore.YELLOW}Clinical Notes:{Style.RESET_ALL}\")\n",
    "                notes = top_result['CLINICAL_NOTES']\n",
    "                if len(notes) > 800:\n",
    "                    notes = notes[:800] + \"...\"\n",
    "                \n",
    "                # Wrap text for better readability\n",
    "                wrapped_notes = textwrap.fill(notes, width=100)\n",
    "                print(wrapped_notes)\n",
    "                \n",
    "                # Show observations if available\n",
    "                if top_result['DESCRIPTION_OBSERVATIONS']:\n",
    "                    print(f\"\\n{Fore.YELLOW}Observations:{Style.RESET_ALL}\")\n",
    "                    obs = top_result['DESCRIPTION_OBSERVATIONS']\n",
    "                    if len(obs) > 400:\n",
    "                        obs = obs[:400] + \"...\"\n",
    "                    print(textwrap.fill(obs, width=100))\n",
    "                \n",
    "                # Show conditions if available\n",
    "                if top_result['DESCRIPTION_CONDITIONS']:\n",
    "                    print(f\"\\n{Fore.YELLOW}Conditions:{Style.RESET_ALL}\")\n",
    "                    cond = top_result['DESCRIPTION_CONDITIONS']\n",
    "                    if len(cond) > 400:\n",
    "                        cond = cond[:400] + \"...\"\n",
    "                    print(textwrap.fill(cond, width=100))\n",
    "\n",
    "# Run the test function\n",
    "if __name__ == \"__main__\":\n",
    "    test_hybrid_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a061cdd8",
   "metadata": {},
   "source": [
    "You may have noticed that by inverting the weights of vector and keyword search, you got different results. For example, by more heavily weighing keyword search in the query, most results will include the string \"diabetes\". When weighing semantic search more heavily, you might have noticed that the top results included phrases such as \"Insulin therapy,\" even if the word \"diabetes\" was not present."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
