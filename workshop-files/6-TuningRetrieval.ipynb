{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "682b0195",
   "metadata": {},
   "source": [
    "## 6. Tuning Your Retrieval Mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebae88ef",
   "metadata": {},
   "source": [
    "You're about to explore how we can enhance the way we retrieve relevant patient data from a medical dataset using various techniques. We will guide you through running a basic vector search in InterSystems IRIS, and refining results with advanced methods like weighted scoring and hybrid search. Follow along with the steps below, and we'll analyze the outputs together to see how each technique improves efficient retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3202ca8a",
   "metadata": {},
   "source": [
    "### InterSystems IRIS Vector Search: An Overview\n",
    "InterSystems IRIS Vector Search allows us to store and query high-dimensional vector embeddings within a relational database. These embeddings represent unstructured data like clinical notes as numerical vectors, enabling semantic similarity comparisons. This means we can find patient encounters that are contextually similar to a query, using SQL operations enhanced by VECTORs.By integrating these capabilities into standard SQL operations, IRIS transforms your relational database into a high-performance hybrid vector database—ready to support next-generation AI applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822ddf82",
   "metadata": {},
   "source": [
    "### Step 1: Connecting to InterSystems IRIS and Viewing the Dataset\n",
    "Let's start by connecting to the InterSystems IRIS database to access our medical dataset. Run the code block provided in the notebook to establish this connection and display a snippet of the data.\n",
    "\n",
    "In this section for this workshop, there is a set of medical data that will be used for experimentation. The data set includes ~1,500 patient encounters, each with structured and coded medical data. With each encounter, however, is also a generated clinical summary note that provides more context about the patient. This might include things such as their commuting situation, their mood during the encounter, or other information not easily categorized into a structured encounter record.\n",
    "\n",
    "Run the block of code below to initiate a connection to InterSystems IRIS and view a snippet of this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b612b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "username = '_SYSTEM'\n",
    "password = 'SYS'\n",
    "hostname = 'IRIS'\n",
    "port = 1972\n",
    "namespace = 'IRISAPP'\n",
    "CONNECTION_STRING = f\"iris://{username}:{password}@{hostname}:{port}/{namespace}\"\n",
    "engine = create_engine(CONNECTION_STRING)\n",
    "\n",
    "df = pd.read_sql(\"SELECT * FROM GenAI.Encounters\", engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16017fd7",
   "metadata": {},
   "source": [
    "Notice that in addition to structured data—such as codes, costs, and standardized descriptions of the encounters—there are also columns with unstructured observations and notes, and accompanying vector embeddings. These vector embeddings will help a generative AI application retrieve relevant chunks of data from this set of patient encounters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d31ec47",
   "metadata": {},
   "source": [
    "### Step 2: Running a Simple Vector Search\n",
    "In this step, we’ll execute a basic vector search to find patient encounters similar to a query input.\n",
    "\n",
    "A simple vector search demonstrates how InterSystems IRIS compares embeddings to find semantically relevant results. For example, querying for something like \"Headache\" would return encounters with similar clinical notes, even if the exact words differ. This is the starting point for understanding retrieval based on meaning rather than keywords\n",
    "\n",
    "First, run the following line of code to select the sentence transformer model that will be used to create an embedding from your search term. The embedding model you use to embed your search queries should be compatible with the model used to create embeddings in your data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d6d3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01801dba",
   "metadata": {},
   "source": [
    "Run the next module, optionally replacing \"Headache\" with a search term of your choice. This module will create and print an embedding for the search term you have entered. You will see that the embedding, even for a simple search term, consists of 384 dimensions—the number of dimensions in the FastEmbed embeddings model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f746e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_search = \"Headache\"\n",
    "search_vector = model.encode(note_search, normalize_embeddings=True).tolist() # Convert search phrase into a vector\n",
    "print(search_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c81acfe",
   "metadata": {},
   "source": [
    "Now let's run a vector search against our CLINICAL_NOTES field using your search term. With the code below, you will retrieve the top three chunks from the CLINICAL_NOTES field in your data set that are deemed most similar to the search term you provided. The results will be displayed in a Pandas DataFrame for easy viewing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c76093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "vector_str = \",\".join(str(x) for x in search_vector)\n",
    "## print(vector_str)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    with conn.begin():\n",
    "        sql = text(\"\"\"\n",
    "            SELECT TOP 3 ENCOUNTER_ID, CLINICAL_NOTES\n",
    "            FROM GenAI.encounters\n",
    "            ORDER BY VECTOR_DOT_PRODUCT(CLINICAL_NOTES_Vector, TO_VECTOR(:search_vector)) DESC\n",
    "        \"\"\")\n",
    "        results = conn.execute(sql, {\"search_vector\": vector_str}).fetchall()\n",
    "\n",
    "# Display results\n",
    "df = pd.DataFrame(results)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64968f8",
   "metadata": {},
   "source": [
    "### Step 3: Searching across multiple vectorized fields\n",
    "Let's now consider that you may want to search across more than just your CLINICAL_NOTES field. To improve relevance, we’ll break down similarity across different data categories (notes, observations, etc.) to see which aspects contribute most to the match. This will help us fine-tune our search.\n",
    "\n",
    "In the block below, you will notice that similarities are being calculated between your search term and all five vectorized fields in the data set. Then, the results are being ordered by the greatest similarity match.\n",
    "\n",
    "In the result set that follows, explore the similarity scores provided. Sometimes one field provides a particularly good match, while others do not.\n",
    "\n",
    "Enter whatever search term you would like in the note_search variable. Feel free to play around with multiple searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc1549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_search = \"Pregnancy complications\"\n",
    "search_vector = model.encode(note_search, normalize_embeddings=True).tolist() # Convert search phrase into a vector\n",
    "## print(search_vector)\n",
    "\n",
    "vector_str = \",\".join(str(x) for x in search_vector) \n",
    "\n",
    "with engine.connect() as conn:\n",
    "    with conn.begin():\n",
    "        sql = text(\"\"\"\n",
    "            SELECT TOP 5\n",
    "                ENCOUNTER_ID,\n",
    "                CLINICAL_NOTES,\n",
    "                DESCRIPTION_OBSERVATIONS,\n",
    "                DESCRIPTION_CONDITIONS,\n",
    "                DESCRIPTION_PROCEDURES,\n",
    "                DESCRIPTION_MEDICATIONS,\n",
    "                VECTOR_DOT_PRODUCT (CLINICAL_NOTES_Vector, TO_VECTOR(:search_vector))\n",
    "                    AS sim_notes,\n",
    "                VECTOR_DOT_PRODUCT(DESCRIPTION_OBSERVATIONS_Vector, TO_VECTOR(:search_vector))\n",
    "                    AS sim_obs,\n",
    "                VECTOR_DOT_PRODUCT(DESCRIPTION_CONDITIONS_Vector,   TO_VECTOR(:search_vector))\n",
    "                    AS sim_cond,\n",
    "                VECTOR_DOT_PRODUCT(DESCRIPTION_PROCEDURES_Vector,   TO_VECTOR(:search_vector))\n",
    "                    AS sim_proc,\n",
    "                VECTOR_DOT_PRODUCT(DESCRIPTION_MEDICATIONS_Vector,  TO_VECTOR(:search_vector))\n",
    "                    AS sim_med\n",
    "            FROM GenAI.encounters\n",
    "            ORDER BY GREATEST(\n",
    "                VECTOR_DOT_PRODUCT(CLINICAL_NOTES_Vector,           TO_VECTOR(:search_vector)),\n",
    "                VECTOR_DOT_PRODUCT(DESCRIPTION_OBSERVATIONS_Vector, TO_VECTOR(:search_vector)),\n",
    "                VECTOR_DOT_PRODUCT(DESCRIPTION_CONDITIONS_Vector,   TO_VECTOR(:search_vector)),\n",
    "                VECTOR_DOT_PRODUCT(DESCRIPTION_PROCEDURES_Vector,   TO_VECTOR(:search_vector)),\n",
    "                VECTOR_DOT_PRODUCT(DESCRIPTION_MEDICATIONS_Vector,  TO_VECTOR(:search_vector))\n",
    ") DESC\n",
    "\n",
    "        \"\"\")\n",
    "        results = conn.execute(sql, {\"search_vector\": vector_str}).fetchall()\n",
    "df = pd.DataFrame(results, columns=[\n",
    "    \"ENCOUNTER_ID\",\n",
    "    \"CLINICAL_NOTES\", \"DESCRIPTION_OBSERVATIONS\", \"DESCRIPTION_CONDITIONS\",\n",
    "    \"DESCRIPTION_PROCEDURES\", \"DESCRIPTION_MEDICATIONS\",\n",
    "    \"sim_notes\",\n",
    "    \"sim_obs\",\n",
    "    \"sim_cond\",\n",
    "    \"sim_proc\",\n",
    "    \"sim_med\"\n",
    "])\n",
    "df[\"DESCRIPTION_OBSERVATIONS\"] = df[\"DESCRIPTION_OBSERVATIONS\"].str[:250]\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4dfba4",
   "metadata": {},
   "source": [
    "Looking at the results, notice how ENCOUNTER_ID 1260 has a higher sim_proc score (0.235474) compared to other categories, suggesting the procedures described are more similar to the query. Meanwhile, ENCOUNTER_ID 910 shows higher scores across sim_notes, sim_cond, and sim_med (all 0.235365), indicating broader relevance. This breakdown reveals varying contributions from different data types, but it’s not yet a unified ranking ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021dc4cd",
   "metadata": {},
   "source": [
    "Diff with VECTOR DOT PRODUCT and COSINE SIMILARITY\n",
    "Dot Product: Faster computation but sensitive to vector magnitude\n",
    "Cosine Similarity: Magnitude-independent but slightly more computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09081c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_search = \"Pregnancy complications\"\n",
    "search_vector = model.encode(note_search, normalize_embeddings=True).tolist() # Convert search phrase into a vector\n",
    "## print(search_vector)\n",
    "\n",
    "vector_str = \",\".join(str(x) for x in search_vector) \n",
    "\n",
    "with engine.connect() as conn:\n",
    "    with conn.begin():\n",
    "        sql = text(\"\"\"\n",
    "            SELECT TOP 5\n",
    "                ENCOUNTER_ID,\n",
    "                CLINICAL_NOTES,\n",
    "                DESCRIPTION_OBSERVATIONS,\n",
    "                DESCRIPTION_CONDITIONS,\n",
    "                DESCRIPTION_PROCEDURES,\n",
    "                DESCRIPTION_MEDICATIONS,\n",
    "                VECTOR_COSINE (CLINICAL_NOTES_Vector, TO_VECTOR(:search_vector))\n",
    "                    AS sim_notes,\n",
    "                VECTOR_COSINE (DESCRIPTION_OBSERVATIONS_Vector, TO_VECTOR(:search_vector))\n",
    "                    AS sim_obs,\n",
    "                VECTOR_COSINE (DESCRIPTION_CONDITIONS_Vector,   TO_VECTOR(:search_vector))\n",
    "                    AS sim_cond,\n",
    "                VECTOR_COSINE (DESCRIPTION_PROCEDURES_Vector,   TO_VECTOR(:search_vector))\n",
    "                    AS sim_proc,\n",
    "                VECTOR_COSINE(DESCRIPTION_MEDICATIONS_Vector,  TO_VECTOR(:search_vector))\n",
    "                    AS sim_med\n",
    "            FROM GenAI.encounters\n",
    "            ORDER BY GREATEST(\n",
    "                VECTOR_COSINE (CLINICAL_NOTES_Vector,           TO_VECTOR(:search_vector)),\n",
    "                VECTOR_COSINE (DESCRIPTION_OBSERVATIONS_Vector, TO_VECTOR(:search_vector)),\n",
    "                VECTOR_COSINE (DESCRIPTION_CONDITIONS_Vector,   TO_VECTOR(:search_vector)),\n",
    "                VECTOR_COSINE (DESCRIPTION_PROCEDURES_Vector,   TO_VECTOR(:search_vector)),\n",
    "                VECTOR_COSINE (DESCRIPTION_MEDICATIONS_Vector,  TO_VECTOR(:search_vector))\n",
    ") DESC\n",
    "\n",
    "        \"\"\")\n",
    "        results = conn.execute(sql, {\"search_vector\": vector_str}).fetchall()\n",
    "df = pd.DataFrame(results, columns=[\n",
    "    \"ENCOUNTER_ID\",\n",
    "    \"CLINICAL_NOTES\", \"DESCRIPTION_OBSERVATIONS\", \"DESCRIPTION_CONDITIONS\",\n",
    "    \"DESCRIPTION_PROCEDURES\", \"DESCRIPTION_MEDICATIONS\",\n",
    "    \"sim_notes\",\n",
    "    \"sim_obs\",\n",
    "    \"sim_cond\",\n",
    "    \"sim_proc\",\n",
    "    \"sim_med\"\n",
    "])\n",
    "df[\"DESCRIPTION_OBSERVATIONS\"] = df[\"DESCRIPTION_OBSERVATIONS\"].str[:250]\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faba341",
   "metadata": {},
   "source": [
    "you're noticing that above queries using VECTOR_DOT_PRODUCT and VECTOR_COSINE produce similar results. This is actually expected when working with normalized embeddings.\n",
    "\n",
    "Why They Produce Similar Results\n",
    "The key is in the embedding generation:\n",
    "\n",
    "search_vector = model.encode(note_search, normalize_embeddings=True).tolist()\n",
    "When you set normalize_embeddings=True, your model is creating unit vectors (vectors with length 1). With normalized vectors:\n",
    "\n",
    "Cosine Similarity = Dot Product: For unit vectors, the dot product is mathematically equivalent to cosine similarity.\n",
    "Mathematical Explanation (if needed)\n",
    "Cosine similarity is defined as: cos(θ) = (A·B)/(|A|·|B|)\n",
    "When |A| = |B| = 1 (normalized vectors), this simplifies to: cos(θ) = A·B\n",
    "\n",
    "In hybrid search function later, we will be using cosine similarity with normalized vectors, which is a common best practice for semantic search.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcac455",
   "metadata": {},
   "source": [
    "### Implementing Weight Adjustments for Multiple Vector Fields\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c43d29",
   "metadata": {},
   "source": [
    "**Define Weights:** Assign weights to each vector field. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeba311",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'sim_notes': 0.25,\n",
    "    'sim_obs': 0.35,\n",
    "    'sim_cond': 0.1,\n",
    "    'sim_proc': 0.2,\n",
    "    'sim_med': 0.1\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e747757",
   "metadata": {},
   "source": [
    "**Modify the SQL Query**\n",
    "Adjust the SQL query to multiply each similarity score by its corresponding weight and sum them up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff8d3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_search = \"diabetes\"\n",
    "search_vector = model.encode(note_search, normalize_embeddings=True).tolist()  # Convert search phrase into a vector\n",
    "vector_str = \",\".join(str(x) for x in search_vector)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    with conn.begin():\n",
    "        sql = text(f\"\"\"\n",
    "            SELECT TOP 5\n",
    "                ENCOUNTER_ID,\n",
    "                CLINICAL_NOTES,\n",
    "                DESCRIPTION_OBSERVATIONS,\n",
    "                DESCRIPTION_CONDITIONS,\n",
    "                DESCRIPTION_PROCEDURES,\n",
    "                DESCRIPTION_MEDICATIONS,\n",
    "                sim_notes,\n",
    "                sim_obs,\n",
    "                sim_cond,\n",
    "                sim_proc,\n",
    "                sim_med,\n",
    "                (\n",
    "                    sim_notes * {weights['sim_notes']} +\n",
    "                    sim_obs * {weights['sim_obs']} +\n",
    "                    sim_cond * {weights['sim_cond']} +\n",
    "                    sim_proc * {weights['sim_proc']} +\n",
    "                    sim_med * {weights['sim_med']}\n",
    "                ) AS weighted_sim\n",
    "            FROM (\n",
    "                SELECT\n",
    "                    ENCOUNTER_ID,\n",
    "                    CLINICAL_NOTES,\n",
    "                    DESCRIPTION_OBSERVATIONS,\n",
    "                    DESCRIPTION_CONDITIONS,\n",
    "                    DESCRIPTION_PROCEDURES,\n",
    "                    DESCRIPTION_MEDICATIONS,\n",
    "                    VECTOR_DOT_PRODUCT(CLINICAL_NOTES_Vector, TO_VECTOR(:search_vector)) AS sim_notes,\n",
    "                    VECTOR_DOT_PRODUCT(DESCRIPTION_OBSERVATIONS_Vector, TO_VECTOR(:search_vector)) AS sim_obs,\n",
    "                    VECTOR_DOT_PRODUCT(DESCRIPTION_CONDITIONS_Vector, TO_VECTOR(:search_vector)) AS sim_cond,\n",
    "                    VECTOR_DOT_PRODUCT(DESCRIPTION_PROCEDURES_Vector, TO_VECTOR(:search_vector)) AS sim_proc,\n",
    "                    VECTOR_DOT_PRODUCT(DESCRIPTION_MEDICATIONS_Vector, TO_VECTOR(:search_vector)) AS sim_med\n",
    "                FROM GenAI.encounters\n",
    "            ) AS subquery\n",
    "            ORDER BY weighted_sim DESC\n",
    "        \"\"\")\n",
    "        results = conn.execute(sql, {\"search_vector\": vector_str}).fetchall()\n",
    "\n",
    "df = pd.DataFrame(results, columns=[\n",
    "    \"ENCOUNTER_ID\",\n",
    "    \"CLINICAL_NOTES\", \"DESCRIPTION_OBSERVATIONS\", \"DESCRIPTION_CONDITIONS\",\n",
    "    \"DESCRIPTION_PROCEDURES\", \"DESCRIPTION_MEDICATIONS\",\n",
    "    \"sim_notes\",\n",
    "    \"sim_obs\",\n",
    "    \"sim_cond\",\n",
    "    \"sim_proc\",\n",
    "    \"sim_med\",\n",
    "    \"weighted_sim\"\n",
    "])\n",
    "df[\"DESCRIPTION_OBSERVATIONS\"] = df[\"DESCRIPTION_OBSERVATIONS\"].str[:250]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b56fb1",
   "metadata": {},
   "source": [
    "## Hybrid Search\n",
    "Combine keyword-based search with vector-based search for more comprehensive results. For example, you can use a text search on the `note` field and combine it with the vector search.\n",
    "The hybrid search combines the strengths of both vector-based semantic search and traditional keyword search, which can provide more relevant results than either method alone. Vector search is good at understanding semantic meaning, while keyword search can catch exact matches that might be missed by the embedding model.\n",
    "You can adjust the `vector_weight` and `keyword_weight` parameters to fine-tune the balance between semantic similarity and keyword matching based on your specific use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8779cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_search(query, engine, model, top_n=5, vector_weight=0.7, keyword_weight=0.3):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - query: Search query string\n",
    "    - engine: SQLAlchemy engine with connection to InterSystems IRIS\n",
    "    - model: model for embeddings\n",
    "    - top_n: Number of results to return\n",
    "    - vector_weight: Weight for vector search results (0.0 to 1.0)\n",
    "    - keyword_weight: Weight for keyword search results (0.0 to 1.0)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Perform vector search\n",
    "    search_vector = model.encode(query, normalize_embeddings=True).tolist()\n",
    "    vector_str = \",\".join(str(x) for x in search_vector)\n",
    "    \n",
    "    with engine.connect() as conn:\n",
    "        vector_sql = text(f\"\"\"\n",
    "            SELECT \n",
    "                TOP {top_n * 2}\n",
    "                ENCOUNTER_ID,\n",
    "                CLINICAL_NOTES,\n",
    "                DESCRIPTION_OBSERVATIONS,\n",
    "                DESCRIPTION_CONDITIONS,\n",
    "                DESCRIPTION_PROCEDURES,\n",
    "                DESCRIPTION_MEDICATIONS,\n",
    "                VECTOR_COSINE(CLINICAL_NOTES_Vector, TO_VECTOR(:search_vector)) AS sim_notes,\n",
    "                VECTOR_COSINE(DESCRIPTION_OBSERVATIONS_Vector, TO_VECTOR(:search_vector)) AS sim_obs,\n",
    "                VECTOR_COSINE(DESCRIPTION_CONDITIONS_Vector, TO_VECTOR(:search_vector)) AS sim_cond,\n",
    "                VECTOR_COSINE(DESCRIPTION_PROCEDURES_Vector, TO_VECTOR(:search_vector)) AS sim_proc,\n",
    "                VECTOR_COSINE(DESCRIPTION_MEDICATIONS_Vector, TO_VECTOR(:search_vector)) AS sim_med,\n",
    "                (\n",
    "                    VECTOR_COSINE(CLINICAL_NOTES_Vector, TO_VECTOR(:search_vector)) * {weights['sim_notes']} +\n",
    "                    VECTOR_COSINE(DESCRIPTION_OBSERVATIONS_Vector, TO_VECTOR(:search_vector)) * {weights['sim_obs']} +\n",
    "                    VECTOR_COSINE(DESCRIPTION_CONDITIONS_Vector, TO_VECTOR(:search_vector)) * {weights['sim_cond']} +\n",
    "                    VECTOR_COSINE(DESCRIPTION_PROCEDURES_Vector, TO_VECTOR(:search_vector)) * {weights['sim_proc']} +\n",
    "                    VECTOR_COSINE(DESCRIPTION_MEDICATIONS_Vector, TO_VECTOR(:search_vector)) * {weights['sim_med']}\n",
    "                ) AS vector_score\n",
    "            FROM GenAI.encounters\n",
    "            ORDER BY vector_score DESC\n",
    "        \"\"\")\n",
    "        \n",
    "        vector_results = conn.execute(vector_sql, {\"search_vector\": vector_str}).fetchall()\n",
    "        \n",
    "        # Step 2: Perform keyword search\n",
    "        # Extract keywords (simple implementation)\n",
    "        keywords = [word.lower() for word in query.split() if len(word) > 3]\n",
    "        if not keywords:\n",
    "            keywords = [query.lower()]\n",
    "        \n",
    "        # Build LIKE conditions for each keyword\n",
    "        like_conditions = []\n",
    "        for field in ['CLINICAL_NOTES', 'DESCRIPTION_OBSERVATIONS', 'DESCRIPTION_CONDITIONS', \n",
    "                     'DESCRIPTION_PROCEDURES', 'DESCRIPTION_MEDICATIONS']:\n",
    "            for keyword in keywords:\n",
    "                like_conditions.append(f\"{field} LIKE '%{keyword}%'\")\n",
    "        \n",
    "        where_clause = \" OR \".join(like_conditions)\n",
    "        \n",
    "        # Keyword search query\n",
    "        keyword_sql = text(f\"\"\"\n",
    "            SELECT \n",
    "                TOP {top_n * 2}\n",
    "                ENCOUNTER_ID,\n",
    "                CLINICAL_NOTES,\n",
    "                DESCRIPTION_OBSERVATIONS,\n",
    "                DESCRIPTION_CONDITIONS,\n",
    "                DESCRIPTION_PROCEDURES,\n",
    "                DESCRIPTION_MEDICATIONS,\n",
    "                (\n",
    "                    {\" + \".join([f\"(CASE WHEN {field} LIKE '%{keyword}%' THEN 1 ELSE 0 END)\" \n",
    "                                for field in ['CLINICAL_NOTES', 'DESCRIPTION_OBSERVATIONS', \n",
    "                                             'DESCRIPTION_CONDITIONS', 'DESCRIPTION_PROCEDURES', \n",
    "                                             'DESCRIPTION_MEDICATIONS']\n",
    "                                for keyword in keywords])}\n",
    "                ) AS keyword_score\n",
    "            FROM GenAI.encounters\n",
    "            WHERE {where_clause}\n",
    "            ORDER BY keyword_score DESC\n",
    "        \"\"\")\n",
    "        \n",
    "        keyword_results = conn.execute(keyword_sql).fetchall()\n",
    "    \n",
    "    # Step 3: Convert results to DataFrames\n",
    "    vector_df = pd.DataFrame(vector_results, columns=[\n",
    "        \"ENCOUNTER_ID\", \"CLINICAL_NOTES\", \"DESCRIPTION_OBSERVATIONS\", \n",
    "        \"DESCRIPTION_CONDITIONS\", \"DESCRIPTION_PROCEDURES\", \"DESCRIPTION_MEDICATIONS\",\n",
    "        \"sim_notes\", \"sim_obs\", \"sim_cond\", \"sim_proc\", \"sim_med\", \"vector_score\"\n",
    "    ])\n",
    "    \n",
    "    keyword_df = pd.DataFrame(keyword_results, columns=[\n",
    "        \"ENCOUNTER_ID\", \"CLINICAL_NOTES\", \"DESCRIPTION_OBSERVATIONS\", \n",
    "        \"DESCRIPTION_CONDITIONS\", \"DESCRIPTION_PROCEDURES\", \"DESCRIPTION_MEDICATIONS\",\n",
    "        \"keyword_score\"\n",
    "    ])\n",
    "    \n",
    "    # Step 4: Normalize scores to 0-1 range\n",
    "    if not vector_df.empty:\n",
    "        # UPDATED: Convert string to numeric values\n",
    "        vector_df['vector_score'] = pd.to_numeric(vector_df['vector_score'], errors='coerce')\n",
    "        max_vector_score = vector_df['vector_score'].max()\n",
    "        if pd.notnull(max_vector_score) and max_vector_score > 0:\n",
    "            vector_df['vector_score_norm'] = vector_df['vector_score'] / max_vector_score\n",
    "        else:\n",
    "            vector_df['vector_score_norm'] = vector_df['vector_score']\n",
    "    \n",
    "    if not keyword_df.empty:\n",
    "        # UPDATED: Convert string to numeric values\n",
    "        keyword_df['keyword_score'] = pd.to_numeric(keyword_df['keyword_score'], errors='coerce')\n",
    "        max_keyword_score = keyword_df['keyword_score'].max()\n",
    "        if pd.notnull(max_keyword_score) and max_keyword_score > 0:\n",
    "            keyword_df['keyword_score_norm'] = keyword_df['keyword_score'] / max_keyword_score\n",
    "        else:\n",
    "            keyword_df['keyword_score_norm'] = keyword_df['keyword_score']\n",
    "    \n",
    "    # Step 5: Merge results\n",
    "    # Start with all vector results\n",
    "    combined_results = vector_df.copy() if not vector_df.empty else pd.DataFrame()\n",
    "\n",
    "    # Add keyword score column (0 for entries only in vector results)\n",
    "    if not combined_results.empty:\n",
    "        combined_results['keyword_score'] = 0\n",
    "        combined_results['keyword_score_norm'] = 0\n",
    "\n",
    "    # Add keyword results not already in vector results\n",
    "    if not keyword_df.empty:\n",
    "        # Find keyword results not in vector results\n",
    "        if not combined_results.empty:\n",
    "            keyword_only = keyword_df[~keyword_df['ENCOUNTER_ID'].isin(combined_results['ENCOUNTER_ID'])].copy()  # Added .copy()\n",
    "        else:\n",
    "            keyword_only = keyword_df.copy()  # Added .copy()\n",
    "            \n",
    "        # Add vector score columns (0 for entries only in keyword results)\n",
    "        if not keyword_only.empty:\n",
    "            # FIX: Use .loc to avoid the SettingWithCopyWarning\n",
    "            for col in ['sim_notes', 'sim_obs', 'sim_cond', 'sim_proc', 'sim_med', 'vector_score', 'vector_score_norm']:\n",
    "                keyword_only.loc[:, col] = 0  # Changed to use .loc\n",
    "            \n",
    "            # Append to combined results\n",
    "            combined_results = pd.concat([combined_results, keyword_only])\n",
    "\n",
    "    # Step 6: Update scores for entries in both result sets\n",
    "    if not combined_results.empty and not keyword_df.empty:\n",
    "        # For each row in combined results that also exists in keyword results\n",
    "        for encounter_id in combined_results['ENCOUNTER_ID']:\n",
    "            keyword_match = keyword_df[keyword_df['ENCOUNTER_ID'] == encounter_id]\n",
    "            if not keyword_match.empty:\n",
    "                # UPDATED: Ensure values are numeric before assignment\n",
    "                combined_results.loc[combined_results['ENCOUNTER_ID'] == encounter_id, 'keyword_score'] = pd.to_numeric(keyword_match['keyword_score'].values[0], errors='coerce')\n",
    "                combined_results.loc[combined_results['ENCOUNTER_ID'] == encounter_id, 'keyword_score_norm'] = pd.to_numeric(keyword_match['keyword_score_norm'].values[0], errors='coerce')\n",
    "    \n",
    "    # Step 7: Calculate hybrid score\n",
    "    if not combined_results.empty:\n",
    "        # UPDATED: Ensure values are numeric before calculation\n",
    "        combined_results['vector_score_norm'] = pd.to_numeric(combined_results['vector_score_norm'], errors='coerce').fillna(0)\n",
    "        combined_results['keyword_score_norm'] = pd.to_numeric(combined_results['keyword_score_norm'], errors='coerce').fillna(0)\n",
    "        \n",
    "        combined_results['hybrid_score'] = (\n",
    "            combined_results['vector_score_norm'] * vector_weight + \n",
    "            combined_results['keyword_score_norm'] * keyword_weight\n",
    "        )\n",
    "        \n",
    "        # Sort by hybrid score\n",
    "        combined_results = combined_results.sort_values(by='hybrid_score', ascending=False)\n",
    "    \n",
    "    # Step 8: Return top N results\n",
    "    return combined_results.head(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49834937",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"diabetes\"\n",
    "results_df = hybrid_search(\n",
    "    query=query,\n",
    "    engine=engine,\n",
    "    model=model,\n",
    "    top_n=5,\n",
    "    vector_weight=0.7,\n",
    "    keyword_weight=0.3\n",
    ")\n",
    "\n",
    "results_df[\"DESCRIPTION_OBSERVATIONS\"] = results_df[\"DESCRIPTION_OBSERVATIONS\"].str[:250]\n",
    "\n",
    "# Display the top 5 results\n",
    "print(f\"Hybrid Search Results for: '{query}'\")\n",
    "results_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2ab9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_hybrid_search():\n",
    "    \"\"\"Test the hybrid search functionality with a sample query.\"\"\"\n",
    "    from dotenv import load_dotenv\n",
    "    from sqlalchemy import create_engine\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    import os\n",
    "    from tabulate import tabulate  # Install with: pip install tabulate\n",
    "    import textwrap\n",
    "    from colorama import Fore, Style, init  # Install with: pip install colorama\n",
    "    \n",
    "    # Initialize colorama for colored terminal output\n",
    "    init(autoreset=True)\n",
    "    \n",
    "   \n",
    "    \n",
    "    # Test queries\n",
    "    test_queries = [\n",
    "        \"diabetes\",\n",
    "        \"diabetic\"\n",
    "    ]\n",
    "    \n",
    "    for query in test_queries:\n",
    "        print(f\"\\n\\n{Fore.CYAN}{'=' * 100}\")\n",
    "        print(f\"{Fore.CYAN}Hybrid Search Results for: {Fore.YELLOW}'{query}'\")\n",
    "        print(f\"{Fore.CYAN}{'=' * 100}\")\n",
    "        \n",
    "        # Perform hybrid search\n",
    "        results = hybrid_search(\n",
    "            query=query,\n",
    "            engine=engine,\n",
    "            model=model,\n",
    "            top_n=5,\n",
    "            vector_weight=0.7,\n",
    "            keyword_weight=0.3\n",
    "        )\n",
    "        \n",
    "        if results.empty:\n",
    "            print(f\"{Fore.RED}No results found.\")\n",
    "        else:\n",
    "            # Format results for display\n",
    "            display_data = []\n",
    "            \n",
    "            for index, row in results.iterrows():\n",
    "                # Truncate and format the clinical notes\n",
    "                notes_preview = textwrap.shorten(row['CLINICAL_NOTES'], width=80, placeholder=\"...\")\n",
    "                \n",
    "                # Format scores with appropriate precision\n",
    "                vector_score = f\"{float(row['vector_score']):.4f}\"\n",
    "                keyword_score = f\"{float(row['keyword_score']):.0f}\"\n",
    "                hybrid_score = f\"{float(row['hybrid_score']):.4f}\"\n",
    "                \n",
    "                display_data.append([\n",
    "                    row['ENCOUNTER_ID'],\n",
    "                    notes_preview,\n",
    "                    vector_score,\n",
    "                    keyword_score,\n",
    "                    hybrid_score\n",
    "                ])\n",
    "            \n",
    "            # Display results in a nicely formatted table\n",
    "            headers = [\n",
    "                f\"{Fore.GREEN}Encounter ID\", \n",
    "                f\"{Fore.GREEN}Clinical Notes Preview\", \n",
    "                f\"{Fore.GREEN}Vector Score\", \n",
    "                f\"{Fore.GREEN}Keyword Score\", \n",
    "                f\"{Fore.GREEN}Hybrid Score\"\n",
    "            ]\n",
    "            \n",
    "            print(tabulate(display_data, headers=headers, tablefmt=\"fancy_grid\"))\n",
    "            \n",
    "            # Print detailed information for the top result\n",
    "            if len(results) > 0:\n",
    "                top_result = results.iloc[0]\n",
    "                \n",
    "                print(f\"\\n{Fore.MAGENTA}Top Result Details:{Style.RESET_ALL}\")\n",
    "                print(f\"{Fore.MAGENTA}{'-' * 100}\")\n",
    "                \n",
    "                # Encounter details\n",
    "                print(f\"{Fore.YELLOW}Encounter ID:{Style.RESET_ALL} {top_result['ENCOUNTER_ID']}\")\n",
    "                print(f\"{Fore.YELLOW}Vector Score:{Style.RESET_ALL} {float(top_result['vector_score']):.4f}\")\n",
    "                print(f\"{Fore.YELLOW}Keyword Score:{Style.RESET_ALL} {float(top_result['keyword_score']):.0f}\")\n",
    "                print(f\"{Fore.YELLOW}Hybrid Score:{Style.RESET_ALL} {float(top_result['hybrid_score']):.4f}\")\n",
    "                \n",
    "                # Format clinical notes with proper wrapping\n",
    "                print(f\"\\n{Fore.YELLOW}Clinical Notes:{Style.RESET_ALL}\")\n",
    "                notes = top_result['CLINICAL_NOTES']\n",
    "                if len(notes) > 800:\n",
    "                    notes = notes[:800] + \"...\"\n",
    "                \n",
    "                # Wrap text for better readability\n",
    "                wrapped_notes = textwrap.fill(notes, width=100)\n",
    "                print(wrapped_notes)\n",
    "                \n",
    "                # Show observations if available\n",
    "                if top_result['DESCRIPTION_OBSERVATIONS']:\n",
    "                    print(f\"\\n{Fore.YELLOW}Observations:{Style.RESET_ALL}\")\n",
    "                    obs = top_result['DESCRIPTION_OBSERVATIONS']\n",
    "                    if len(obs) > 400:\n",
    "                        obs = obs[:400] + \"...\"\n",
    "                    print(textwrap.fill(obs, width=100))\n",
    "                \n",
    "                # Show conditions if available\n",
    "                if top_result['DESCRIPTION_CONDITIONS']:\n",
    "                    print(f\"\\n{Fore.YELLOW}Conditions:{Style.RESET_ALL}\")\n",
    "                    cond = top_result['DESCRIPTION_CONDITIONS']\n",
    "                    if len(cond) > 400:\n",
    "                        cond = cond[:400] + \"...\"\n",
    "                    print(textwrap.fill(cond, width=100))\n",
    "\n",
    "# Run the test function\n",
    "if __name__ == \"__main__\":\n",
    "    test_hybrid_search()"
   ]
  },
   {
    "cell_type": "markdown",
    "id": "integration-section",
    "metadata": {},
    "source": [
     "## 🔄 Integration with Chat Application and Evaluation\n",
     "\n",
     "Now that you've explored different retrieval techniques, let's see how to integrate these improvements into your chat application and measure their impact using DeepEval.\n",
     "\n",
     "### Step 7: Applying Retrieval Improvements to Your Chat App\n",
     "\n",
     "The retrieval techniques you've learned can be integrated into your chat application through the shared RAG module (`rag_module.py`). This ensures that improvements you make here automatically benefit your chat application."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "id": "rag-integration",
    "metadata": {},
    "outputs": [],
    "source": [
     "# Import our shared RAG module\n",
     "from rag_module import WorkshopRAG\n",
     "\n",
     "# Example: Create an enhanced RAG system with custom retrieval\n",
     "print(\"🔧 Demonstrating RAG module integration...\")\n",
     "\n",
     "# Initialize the RAG system\n",
     "rag_system = WorkshopRAG(\n",
     "    collection_name=\"case_reports\",\n",
     "    llm_model=\"gpt-4-turbo\",\n",
     "    temperature=0.0\n",
     ")\n",
     "\n",
     "# Test a query\n",
     "test_question = \"What are the symptoms of pregnancy complications?\"\n",
     "answer, contexts = rag_system.query(test_question)\n",
     "\n",
     "print(f\"\\n📝 Question: {test_question}\")\n",
     "print(f\"🤖 Answer: {answer[:200]}...\")\n",
     "print(f\"📄 Retrieved {len(contexts)} contexts\")\n",
     "\n",
     "print(\"\\n💡 To apply retrieval improvements:\")\n",
     "print(\"   1. Modify the query() method in rag_module.py\")\n",
     "print(\"   2. Implement weighted scoring, hybrid search, etc.\")\n",
     "print(\"   3. Both chat app and evaluation will use the improved retrieval\")"
    ]
   },
   {
    "cell_type": "markdown",
    "id": "evaluation-integration",
    "metadata": {},
    "source": [
     "### Step 8: Measuring Improvement with DeepEval\n",
     "\n",
     "After implementing retrieval improvements, you should measure their impact using the evaluation framework from Notebook 5.\n",
     "\n",
     "**🔄 Recommended Workflow:**\n",
     "\n",
     "1. **Baseline Measurement**: Run Notebook 5 (`5-TestFirstFramework.ipynb`) to get baseline metrics\n",
     "2. **Apply Improvements**: Modify `rag_module.py` with techniques from this notebook\n",
     "3. **Re-evaluate**: Run Notebook 5 again to measure improvement\n",
     "4. **Compare Results**: Analyze which changes improved performance\n",
     "\n",
     "**📊 Key Metrics to Watch:**\n",
     "- **Answer Relevancy**: Did better retrieval lead to more relevant answers?\n",
     "- **Contextual Relevancy**: Are the retrieved contexts more relevant?\n",
     "- **Faithfulness**: Are answers more faithful to the retrieved information?\n",
     "- **Contextual Recall**: Is the system finding more relevant information?\n",
     "\n",
     "**💡 Example Improvements to Test:**\n",
     "- Weighted scoring across multiple fields (notes, conditions, procedures)\n",
     "- Hybrid search combining vector and keyword search\n",
     "- Custom similarity thresholds\n",
     "- Multi-step retrieval strategies"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "id": "evaluation-reminder",
    "metadata": {},
    "outputs": [],
    "source": [
     "print(\"🧪 Ready to measure your improvements!\")\n",
     "print(\"\\n📋 Next Steps:\")\n",
     "print(\"   1. Choose a retrieval improvement from this notebook\")\n",
     "print(\"   2. Implement it in rag_module.py\")\n",
     "print(\"   3. Test in the chat app (Chat3-GuardrailsAndHistory-Refactored.py)\")\n",
     "print(\"   4. Run evaluation (5-TestFirstFramework.ipynb)\")\n",
     "print(\"   5. Compare metrics to see if performance improved\")\n",
     "\n",
     "print(\"\\n🎯 This creates a complete feedback loop:\")\n",
     "print(\"   Experiment → Implement → Test → Evaluate → Improve\")\n",
     "\n",
     "print(\"\\n📈 Track these metrics across iterations:\")\n",
     "metrics = [\n",
     "    \"Answer Relevancy\",\n",
     "    \"Faithfulness\", \n",
     "    \"Contextual Relevancy\",\n",
     "    \"Contextual Recall\"\n",
     "]\n",
     "for metric in metrics:\n",
     "    print(f\"   • {metric}\")\n",
     "\n",
     "print(\"\\n🚀 Happy experimenting!\")"
    ]
   },
   {
    "cell_type": "markdown",
    "id": "conclusion",
    "metadata": {},
    "source": [
     "## 🎯 Conclusion\n",
     "\n",
     "You've now learned how to:\n",
     "\n",
     "✅ **Tune retrieval mechanisms** using various IRIS vector search techniques  \n",
     "✅ **Implement weighted scoring** across multiple vectorized fields  \n",
     "✅ **Use hybrid search** combining vector and keyword approaches  \n",
     "✅ **Integrate improvements** into your chat application via the shared RAG module  \n",
     "✅ **Measure impact** using DeepEval's comprehensive evaluation framework  \n",
     "\n",
     "**🔄 The Complete Workshop Loop:**\n",
     "1. **Build** your RAG system (Notebooks 1-4)\n",
     "2. **Evaluate** with test-first framework (Notebook 5)\n",
     "3. **Improve** retrieval mechanisms (Notebook 6)\n",
     "4. **Re-evaluate** to measure improvements (Back to Notebook 5)\n",
     "5. **Iterate** until you achieve desired performance\n",
     "\n",
     "This systematic approach ensures your RAG improvements are data-driven and measurable!"
    ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
