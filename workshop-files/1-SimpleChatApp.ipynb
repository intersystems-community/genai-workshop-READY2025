{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Running a Simple Chat Application\n",
    "Welcome to *AI-Enabling Your Applications with InterSystems IRIS!* Throughout this workshop, you will use InterSystems IRIS and several different Python libraries to create a generative AI application that utilizes two different sets of healthcare data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch the Pass-Through Chat App\n",
    "Throughout this workshop, you will run modules of code within these notebook files. You can run these modules by pressing the small play button on each module, or you can press *Shift+Enter* to run a given module of code.\n",
    "\n",
    "In the first section, you are running a chat application that serves **only as a passthrough to an LLM.** This means that your queries are passed directly to the LLM being used by the app, and it is not aware of any specific data other than whatever the model was trained on.\n",
    "\n",
    "Run the two modules below to launch a simple pass-through chat application, which is based on the Python file `Chat1-Passthrough.py`. If you see any deprecation warnings, you can ignore them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['STREAMLIT_GENERAL_EMAIL'] = \"\"\n",
    "os.environ['STREAMLIT_THEME_PRIMARYCOLOR'] = \"#5863ff\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  You can now view your Streamlit app in your browser.\n",
      "\n",
      "  Local URL: http://localhost:8080\n",
      "  Network URL: http://192.168.86.38:8080\n",
      "\n",
      "  For better performance, install the Watchdog module:\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/psulin/.pyenv/versions/3.12.4/envs/genai_workshop/lib/python3.12/site-packages/langchain_community/llms/openai.py:255: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/Users/psulin/.pyenv/versions/3.12.4/envs/genai_workshop/lib/python3.12/site-packages/langchain_community/llms/openai.py:1089: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/Users/psulin/repos/genai-workshop-READY2025/workshop-files/Chat1-Passthrough.py:15: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  st.info(llm(input_text))\n",
      "2025-06-20 08:33:23.161 Uncaught app execution\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/psulin/.pyenv/versions/3.12.4/envs/genai_workshop/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 121, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "             ^^^^^^\n",
      "  File \"/Users/psulin/.pyenv/versions/3.12.4/envs/genai_workshop/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 645, in code_to_exec\n",
      "    exec(code, module.__dict__)\n",
      "  File \"/Users/psulin/repos/genai-workshop-READY2025/workshop-files/Chat1-Passthrough.py\", line 25, in <module>\n",
      "    generate_response(text)\n",
      "  File \"/Users/psulin/repos/genai-workshop-READY2025/workshop-files/Chat1-Passthrough.py\", line 15, in generate_response\n",
      "    st.info(llm(input_text))\n",
      "            ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/psulin/.pyenv/versions/3.12.4/envs/genai_workshop/lib/python3.12/site-packages/langchain_core/_api/deprecation.py\", line 191, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/psulin/.pyenv/versions/3.12.4/envs/genai_workshop/lib/python3.12/site-packages/langchain_core/language_models/llms.py\", line 1315, in __call__\n",
      "    self.generate(\n",
      "  File \"/Users/psulin/.pyenv/versions/3.12.4/envs/genai_workshop/lib/python3.12/site-packages/langchain_core/language_models/llms.py\", line 971, in generate\n",
      "    return self._generate_helper(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/psulin/.pyenv/versions/3.12.4/envs/genai_workshop/lib/python3.12/site-packages/langchain_core/language_models/llms.py\", line 790, in _generate_helper\n",
      "    self._generate(\n",
      "  File \"/Users/psulin/.pyenv/versions/3.12.4/envs/genai_workshop/lib/python3.12/site-packages/langchain_community/llms/openai.py\", line 1178, in _generate\n",
      "    full_response = completion_with_retry(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/psulin/.pyenv/versions/3.12.4/envs/genai_workshop/lib/python3.12/site-packages/langchain_community/llms/openai.py\", line 121, in completion_with_retry\n",
      "    return llm.client.create(**kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/psulin/.pyenv/versions/3.12.4/envs/genai_workshop/lib/python3.12/site-packages/openai/lib/_old_api.py\", line 39, in __call__\n",
      "    raise APIRemovedInV1(symbol=self._symbol)\n",
      "openai.lib._old_api.APIRemovedInV1: \n",
      "\n",
      "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
      "\n",
      "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
      "\n",
      "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
      "\n",
      "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "streamlit run 'Chat1-Passthrough.py' --server.port 8080"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switch to the \"Application\" tab in your lab environment to access the running Streamlit app."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iris-agent",
   "language": "python",
   "name": "iris-agent"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
